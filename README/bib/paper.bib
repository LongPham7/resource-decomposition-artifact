@article{GrodinNSH24,
  author    = {Harrison Grodin and
               Yue Niu and
               Jonathan Sterling and
               Robert Harper},
  title     = {Decalf: {A} Directed, Effectful Cost-Aware Logical Framework},
  journal   = {Proc. {ACM} Program. Lang.},
  volume    = {8},
  number    = {{POPL}},
  pages     = {273--301},
  year      = {2024},
  url       = {https://doi.org/10.1145/3632852},
  doi       = {10.1145/3632852},
  timestamp = {Sat, 10 Feb 2024 18:05:26 +0100},
  biburl    = {https://dblp.org/rec/journals/pacmpl/GrodinNSH24.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{WangWC17,
  author     = {Wang, Peng and Wang, Di and Chlipala, Adam},
  title      = {TiML: a functional language for practical complexity analysis with invariants},
  year       = {2017},
  issue_date = {October 2017},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {1},
  number     = {OOPSLA},
  url        = {https://doi.org/10.1145/3133903},
  doi        = {10.1145/3133903},
  journal    = {Proc. ACM Program. Lang.},
  month      = {oct},
  articleno  = {79},
  numpages   = {26},
  keywords   = {resource-aware type systems, refinement types, asymptotic complexity}
}

@inproceedings{WangKRPH20,
  author    = {Tristan Knoth and Di Wang and Adam Reynolds and Nadia Polikarpova and Jan Hoffmann},
  title     = {{Liquid Resource Types}},
  year      = 2020,
  booktitle = {25th International Conference on Functional Programming (ICFP'20)}
}

@inproceedings{CicekBGGH16,
  author    = {Ezgi Çiçek and Gilles Barthe and Marco Gaboardi and Deepak Garg and Jan Hoffmann},
  title     = {{Relational Cost Analysis}},
  booktitle = {44th Symposium on Principles of Programming Languages (POPL'17)},
  year      = 2017
}

@inproceedings{CicekGA15,
  author    = {{\c{C}}i{\c{c}}ek, Ezgi
               and Garg, Deepak
               and Acar, Umut},
  editor    = {Vitek, Jan},
  title     = {Refinement Types for Incremental Computational Complexity},
  booktitle = {Programming Languages and Systems},
  year      = {2015},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {406--431},
  abstract  = {With recent advances, programs can be compiled to efficiently respond to incremental input changes. However, there is no language-level support for reasoning about the time complexity of incremental updates. Motivated by this gap, we present CostIt, a higher-order functional language with a lightweight refinement type system for proving asymptotic bounds on incremental computation time. Type refinements specify which parts of inputs and outputs may change, as well as dynamic stability, a measure of time required to propagate changes to a program's execution trace, given modified inputs. We prove our type system sound using a new step-indexed cost semantics for change propagation and demonstrate the precision and generality of our technique through examples.},
  isbn      = {978-3-662-46669-8}
}

@inproceedings{Atkey10,
  title     = {Amortised Resource Analysis with Separation Logic},
  booktitle = {Programming Languages and Systems},
  author    = {Atkey, Robert},
  editor    = {Gordon, Andrew D.},
  year      = {2010},
  pages     = {85--103},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  abstract  = {Type-based amortised resource analysis following Hofmann and Jost---where resources are associated with individual elements of data structures and doled out to the programmer under a linear typing discipline---have been successful in providing concrete resource bounds for functional programs, with good support for inference. In this work we translate the idea of amortised resource analysis to imperative languages by embedding a logic of resources, based on Bunched Implications, within Separation Logic. The Separation Logic component allows us to assert the presence and shape of mutable data structures on the heap, while the resource component allows us to state the resources associated with each member of the structure.},
  isbn      = {978-3-642-11957-6}
}

@article{Atkey24,
  author    = {Robert Atkey},
  title     = {Polynomial Time and Dependent Types},
  journal   = {Proc. {ACM} Program. Lang.},
  volume    = {8},
  number    = {{POPL}},
  pages     = {2288--2317},
  year      = {2024},
  url       = {https://doi.org/10.1145/3632918},
  doi       = {10.1145/3632918},
  timestamp = {Mon, 05 Feb 2024 20:23:03 +0100},
  biburl    = {https://dblp.org/rec/journals/pacmpl/Atkey24.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{InferWeb,
  author       = {Facebook, Inc.},
  title        = {{Infer Website - Cost: Runtime Complexity Analysis}},
  year         = {{2024}},
  timestamp    = {Mon, 20 May 2024 11:46 +0100},
  howpublished = {\url{https://fbinfer.com/docs/checker-cost}}
}

@inproceedings{IyerAC22,
  author    = {Rishabh Iyer and Katerina Argyraki and George Candea},
  title     = {Performance Interfaces for Network Functions},
  booktitle = {19th USENIX Symposium on Networked Systems Design and Implementation (NSDI 22)},
  year      = {2022},
  isbn      = {978-1-939133-27-4},
  address   = {Renton, WA},
  pages     = {567--584},
  url       = {https://www.usenix.org/conference/nsdi22/presentation/iyer},
  publisher = {USENIX Association},
  month     = apr
}


@inproceedings{LongH20,
  author    = {Long Pham and Jan Hoffmann},
  title     = {{Typable Fragments of Polynomial Automatic Amortized Resource Analysis}},
  year      = 2021,
  booktitle = {29th EACSL Annual Conference on Computer Science Logic (CSL'21)}
}

@article{Abella2017,
  title      = {Measurement-Based Worst-Case Execution Time Estimation Using the Coefficient of Variation},
  author     = {Abella, Jaume and Padilla, Maria and Castillo, Joan Del and Cazorla, Francisco J.},
  year       = {2017},
  month      = jun,
  journal    = {ACM Transactions on Design Automation of Electronic Systems},
  volume     = {22},
  number     = {4},
  publisher  = {ACM},
  address    = {{New York, NY, USA}},
  issn       = {1084-4309},
  doi        = {10.1145/3065924},
  articleno  = {72},
  numpages   = {29},
  issue_date = {October 2017}
}

@inproceedings{Albert2008costa,
  title      = {{{COSTA}}: {{Design}} and {{Implementation}} of a {{Cost}} and {{Termination Analyzer}} for {{Java Bytecode}}},
  shorttitle = {{{COSTA}}},
  booktitle  = {Formal {{Methods}} for {{Components}} and {{Objects}}},
  author     = {Albert, Elvira and Arenas, Puri and Genaim, Samir and Puebla, German and Zanardini, Damiano},
  feditor    = {{de Boer}, Frank S. and Bonsangue, Marcello M. and Graf, Susanne and {de Roever}, Willem-Paul},
  year       = {2008},
  series     = {Lecture {{Notes}} in {{Computer Science}}},
  volume     = {5382},
  pages      = {113--132},
  publisher  = {{Springer}},
  address    = {{Berlin}},
  doi        = {10.1007/978-3-540-92188-2_5},
  isbn       = {978-3-540-92188-2}
}

@inproceedings{Albert2008,
  author    = {Albert, Elvira
               and Arenas, Puri
               and Genaim, Samir
               and Puebla, Germ{\'a}n},
  editor    = {Alpuente, Mar{\'i}a
               and Vidal, Germ{\'a}n},
  title     = {Automatic Inference of Upper Bounds for Recurrence Relations in Cost Analysis},
  booktitle = {Static Analysis},
  year      = {2008},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {221--237},
  abstract  = {The classical approach to automatic cost analysis consists of two phases. Given a program and some measure of cost, we first produce recurrence relations (RRs) which capture the cost of our program in terms of the size of its input data. Second, we convert such RRs into closed form (i.e., without recurrences). Whereas the first phase has received considerable attention, with a number of cost analyses available for a variety of programming languages, the second phase has received comparatively little attention. In this paper we first study the features of RRs generated by automatic cost analysis and discuss why existing computer algebra systems are not appropriate for automatically obtaining closed form solutions nor upper bounds of them. Then we present, to our knowledge, the first practical framework for the fully automatic generation of reasonably accurate upper bounds of RRs originating from cost analysis of a wide range of programs. It is based on the inference of ranking functions and loop invariants and on partial evaluation.},
  isbn      = {978-3-540-69166-2}
}


@inproceedings{Albert2007,
  title     = {Cost {{Analysis}} of {{Java Bytecode}}},
  booktitle = {Programming {{Languages}} and {{Systems}}},
  author    = {Albert, Elvira and Arenas, Puri and Genaim, Samir and Puebla, German and Zanardini, Damiano},
  feditor   = {De Nicola, Rocco},
  year      = {2007},
  series    = {Lecture {{Notes}} in {{Computer Science}}},
  volume    = {4421},
  pages     = {157--172},
  publisher = {{Springer}},
  address   = {{Berlin}},
  doi       = {10.1007/978-3-540-71316-6_12},
  isbn      = {978-3-540-71316-6}
}

@incollection{Andersen2015,
  author    = {Andersen, Per K. and Vaeth, Michael},
  feditor   = {Balakrishnan, N. and Colton, T.and Everitt, B. and Piegorsch, W. and Ruggeri  F. and Teugel J.~L.},
  title     = {Survival Analysis},
  booktitle = {Wiley StatsRef: Statistics Reference Online},
  year      = {2015},
  doi       = {10.1002/9781118445112.stat02177.pub2},
  publisher = {John Wiley \& Sons, Ltd},
  address   = {Hoboken, NJ, USA}
}

@article{Avanzini2017,
  title      = {Automating Sized-Type Inference for Complexity Analysis},
  author     = {Avanzini, Martin and Dal Lago, Ugo},
  year       = {2017},
  month      = aug,
  journal    = {Proc. ACM Program. Lang.},
  volume     = {1},
  number     = {ICFP},
  publisher  = {{ACM}},
  address    = {{New York, NY, USA}},
  doi        = {10.1145/3110287},
  articleno  = {43},
  numpages   = {29},
  issue_date = {September 2017}
}

@inproceedings{Avanzini2015,
  title     = {Analysing the Complexity of Functional Programs: {{Higher-order}} Meets First-Order},
  booktitle = {Proc. 20th {{ACM SIGPLAN}} International Conference on Functional Programming},
  author    = {Avanzini, Martin and Dal Lago, Ugo and Moser, Georg},
  year      = {2015},
  fseries   = {{{ICFP}} 2015},
  pages     = {152--164},
  publisher = {{ACM}},
  address   = {{New York, NY, USA}},
  doi       = {10.1145/2784731.2784753},
  isbn      = {978-1-4503-3669-7}
}

@article{Avanzini2020,
  title      = {A Modular Cost Analysis for Probabilistic Programs},
  author     = {Avanzini, Martin and Moser, Georg and Schaper, Michael},
  year       = {2020},
  month      = nov,
  journal    = {Proc. ACM Program. Lang.},
  volume     = {4},
  number     = {OOPSLA},
  numpages   = {30},
  pages      = {1--30},
  doi        = {10.1145/3428240},
  pubslisher = {ACM}
}

@article{Avanzini2013,
  title     = {A Combination Framework for Complexity},
  author    = {Avanzini, Martin and Moser, Georg},
  journal   = {Information and Computation},
  volume    = {248},
  pages     = {22--55},
  year      = {2016},
  publisher = {Elsevier},
  doi       = {10.1016/j.ic.2015.12.007}
}

@techreport{Bernat2003,
  title       = {{{pWCET}}: A Tool for Probabilistic Worst-Case Execution Time Analysis of Real-Time Systems},
  author      = {Bernat, Guillem and Colin, Antoine and Petters, Stefan},
  year        = {2003},
  number      = {YCS-2003-353},
  institution = {University of York}
}

@inproceedings{Betts2010,
  title     = {Hybrid Measurement-Based {{WCET}} Analysis at the Source Level Using Object-Level Traces},
  booktitle = {10th International Workshop on Worst-Case Execution Time Analysis},
  author    = {Betts, Adam and Merriam, Nicholas and Bernat, Guillem},
  feditor   = {Lisper, Bj{\"o}rn},
  year      = {2010},
  series    = {{{OpenAccess}} Series in Informatics ({{OASIcs}})},
  volume    = {15},
  pages     = {54--63},
  publisher = {{Schloss Dagstuhl\textendash Leibniz-Zentrum fuer Informatik}},
  address   = {{Dagstuhl, Germany}},
  issn      = {2190-6807},
  doi       = {10.4230/OASIcs.WCET.2010.54},
  isbn      = {978-3-939897-21-7},
  urn       = {urn:nbn:de:0030-drops-28255}
}

@article{Blum1973,
  title   = {Time Bounds for Selection},
  author  = {Blum, Manuel and Floyd, Robert W. and Pratt, Vaughan and Rivest, Ronald L. and Tarjan, Robert E.},
  year    = {1973},
  month   = aug,
  journal = {Journal of Computer and System Sciences},
  volume  = {7},
  number  = {4},
  pages   = {448--461},
  issn    = {0022-0000},
  doi     = {10.1016/S0022-0000(73)80033-9}
}

@inproceedings{Brockschmidt2014,
  title     = {Alternating Runtime and Size Complexity Analysis of Integer Programs},
  booktitle = {Proc. 20th International Conference on Tools and Algorithms for the Construction and Analysis of Systems ({TACAS} 2014)},
  author    = {Brockschmidt, Marc and Emmes, Fabian and Falke, Stephan and Fuhs, Carsten and Giesl, J{\"u}rgen},
  year      = {2014},
  series    = {Lecture Notes in Computer Science},
  volume    = {8413},
  pages     = {140--155},
  publisher = {Springer},
  address   = {Berlin},
  doi       = {10.1007/978-3-642-54862-8_10}
}

@inproceedings{Carbonneaux2015,
  title     = {Compositional Certified Resource Bounds},
  booktitle = {Proc. 36th {{ACM SIGPLAN Conference}} on {{Programming Language Design}} and {{Implementation}}},
  author    = {Carbonneaux, Quentin and Hoffmann, Jan and Shao, Zhong},
  year      = {2015},
  month     = jun,
  fseries   = {{{PLDI}} 2015},
  pages     = {467--478},
  publisher = {{ACM}},
  address   = {{New York, NY, USA}},
  doi       = {10.1145/2737924.2737955},
  isbn      = {978-1-4503-3468-6}
}

@inproceedings{Carbonneaux2017,
  title     = {Automated Resource Analysis with {Coq} Proof Objects},
  booktitle = {Computer Aided Verification},
  author    = {Carbonneaux, Quentin and Hoffmann, Jan and Reps, Thomas and Shao, Zhong},
  editor    = {Majumdar, Rupak and Kun{\v c}ak, Viktor},
  year      = {2017},
  series    = {Lecture Notes in Computer Science},
  pages     = {64--85},
  publisher = {{Springer}},
  address   = {{Cham}},
  doi       = {10.1007/978-3-319-63390-9_4}
}

@article{Casella1985,
  author    = {George Casella},
  title     = {An Introduction to Empirical Bayes Data Analysis},
  journal   = {The American Statistician},
  volume    = {39},
  number    = {2},
  pages     = {83--87},
  year      = {1985},
  publisher = {Taylor \& Francis},
  doi       = {10.1080/00031305.1985.10479400}
}

@article{Cazals2022,
  title     = {Improved Polytope Volume Calculations Based on {{Hamiltonian Monte Carlo}} with Boundary Reflections and Sweet Arithmetics},
  author    = {Cazals, Frederic and Chevallier, Augustin and Pion, Sylvain},
  year      = {2022},
  month     = apr,
  journal   = {Journal of Computational Geometry},
  volume    = {13},
  number    = {1},
  pages     = {52--88},
  issn      = {1920-180X},
  doi       = {10.20382/jocg.v13i1a3},
  copyright = {Copyright (c) 2022 Frederic Cazals, Augustin Chevallier, Sylvain Pion}
}

@inproceedings{Cazorla2013,
  title     = {Upper-Bounding Program Execution Time with Extreme Value Theory},
  booktitle = {13th International Workshop on Worst-Case Execution Time Analysis},
  author    = {Cazorla, Francisco J. and Vardanega, Tullio and Qui{\~n}ones, Eduardo and Abella, Jaume},
  series    = {Open Access Series in Informatics},
  volume    = {30},
  pages     = {64--76},
  year      = {2013},
  publisher = {{Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik}},
  address   = {Wadern},
  doi       = {10.4230/OASIcs.WCET.2013.64}
}

@article{Chalkis2021,
  title      = {Volesti: {{Volume Approximation}} and {{Sampling}} for {{Convex Polytopes}} in {{R}}},
  shorttitle = {Volesti},
  author     = {Chalkis, Apostolos and Fisikopoulos, Vissarion},
  year       = {2021},
  journal    = {The R Journal},
  volume     = {13},
  number     = {2},
  pages      = {642--660},
  doi        = {10.32614/RJ-2021-077},
  issn       = {2073-4859}
}

@article{Chalkis2023,
  title     = {Truncated {{Log-concave Sampling}} for {{Convex Bodies}} with {{Reflective Hamiltonian Monte Carlo}}},
  author    = {Chalkis, Apostolos and Fisikopoulos, Vissarion and Papachristou, Marios and Tsigaridas, Elias},
  year      = {2023},
  month     = jun,
  journal   = {ACM Transactions on Mathematical Software},
  volume    = {49},
  number    = {2},
  articleno = {16},
  numpages  = {25},
  issn      = {0098-3500},
  doi       = {10.1145/3589505}
}

@article{Chargueraud2019,
  title   = {Verifying the {{Correctness}} and {{Amortized Complexity}} of a {{Union-Find Implementation}} in {{Separation Logic}} with {{Time Credits}}},
  author  = {Chargu{\'e}raud, Arthur and Pottier, Fran{\c c}ois},
  year    = {2019},
  month   = mar,
  journal = {Journal of Automated Reasoning},
  volume  = {62},
  number  = {3},
  pages   = {331--365},
  issn    = {1573-0670},
  doi     = {10.1007/s10817-017-9431-7}
}

@article{Chatterjee2019,
  title     = {Non-Polynomial {{Worst-Case Analysis}} of {{Recursive Programs}}},
  author    = {Chatterjee, Krishnendu and Fu, Hongfei and Goharshady, Amir Kafshdar},
  year      = {2019},
  month     = oct,
  journal   = {ACM Transactions on Programming Languages and Systems},
  volume    = {41},
  number    = {4},
  articleno = {20},
  numpages  = {52},
  issn      = {0164-0925},
  doi       = {10.1145/3339984}
}

@inproceedings{Cicek2017,
  title     = {Relational Cost Analysis},
  booktitle = {Proceedings of the 44th {{ACM SIGPLAN Symposium}} on {{Principles}} of {{Programming Languages}}},
  author    = {{\c C}i{\c c}ek, Ezgi and Barthe, Gilles and Gaboardi, Marco and Garg, Deepak and Hoffmann, Jan},
  year      = {2017},
  month     = jan,
  series    = {{{POPL}} '17},
  pages     = {316--329},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/3009837.3009858},
  urldate   = {2022-07-08},
  abstract  = {Establishing quantitative bounds on the execution cost of programs is essential in many areas of computer science such as complexity analysis, compiler optimizations, security and privacy. Techniques based on program analysis, type systems and abstract interpretation are well-studied, but methods for analyzing how the execution costs of two programs compare to each other have not received attention. Naively combining the worst and best case execution costs of the two programs does not work well in many cases because such analysis forgets the similarities between the programs or the inputs. In this work, we propose a relational cost analysis technique that is capable of establishing precise bounds on the difference in the execution cost of two programs by making use of relational properties of programs and inputs. We develop , a refinement type and effect system for a higher-order functional language with recursion and subtyping. The key novelty of our technique is the combination of relational refinements with two modes of typing-relational typing for reasoning about similar computations/inputs and unary typing for reasoning about unrelated computations/inputs. This combination allows us to analyze the execution cost difference of two programs more precisely than a naive non-relational approach. We prove our type system sound using a semantic model based on step-indexed unary and binary logical relations accounting for non-relational and relational reasoning principles with their respective costs. We demonstrate the precision and generality of our technique through examples.},
  isbn      = {978-1-4503-4660-3},
  keywords  = {complexity analysis,Relational reasoning,type and effect systems}
}

@inproceedings{Cicek2020,
  title     = {Static {{Resource Analysis}} at {{Scale}} ({{Extended Abstract}})},
  booktitle = {Proc. 27th International Static Analysis Symposium},
  author    = {{\c C}i{\c c}ek, Ezgi and Bouaziz, Mehdi and Cho, Sungkeun and Distefano, Dino},
  feditor   = {Pichardie, David and Sighireanu, Mihaela},
  year      = {2021},
  series    = {Lecture {{Notes}} in {{Computer Science}}},
  volume    = {12389},
  pages     = {3--6},
  publisher = {{Springer}},
  address   = {{Cham}},
  doi       = {10.1007/978-3-030-65474-0_1},
  isbn      = {978-3-030-65474-0}
}

@inproceedings{Coppa2012,
  title     = {Input-Sensitive Profiling},
  booktitle = {Proc. 33rd {{ACM SIGPLAN Conference}} on {{Programming Language Design}} and {{Implementation}}},
  author    = {Coppa, Emilio and Demetrescu, Camil and Finocchi, Irene},
  year      = {2012},
  month     = jun,
  pages     = {89--98},
  publisher = {{ACM}},
  address   = {{New York, NY, USA}},
  doi       = {10.1145/2254064.2254076},
  isbn      = {978-1-4503-1205-9}
}

@inproceedings{Crary2000,
  title     = {Resource Bound Certification},
  booktitle = {Proc. 27th {{ACM SIGPLAN-SIGACT}} Symposium on Principles of Programming Languages},
  author    = {Crary, Karl and Weirich, Stephnie},
  year      = {2000},
  pages     = {184--198},
  publisher = {{ACM}},
  address   = {{New York, NY, USA}},
  doi       = {10.1145/325694.325716},
  isbn      = {1-58113-125-9}
}

@article{Cutler2020,
  title     = {Denotational Recurrence Extraction for Amortized Analysis},
  author    = {Cutler, Joseph W. and Licata, Daniel R. and Danner, Norman},
  year      = {2020},
  month     = aug,
  journal   = {Proc. ACM Program. Lang.},
  volume    = {4},
  number    = {ICFP},
  articleno = {97},
  numpages  = {29},
  doi       = {10.1145/3408979}
}

@misc{Das2019,
  title         = {Resource-{{Aware Session Types}} for {{Digital Contracts}}},
  author        = {Das, Ankush and Balzer, Stephanie and Hoffmann, Jan and Pfenning, Frank and Santurkar, Ishani},
  eprint        = {1902.06056},
  primaryclass  = {cs},
  publisher     = {{arXiv}},
  archiveprefix = {arxiv},
  fdoi          = {10.48550/arXiv.1902.06056},
  year          = {2019}
}

@inproceedings{Das2017,
  title     = {{ML} for {ML}: Learning Cost Semantics by Experiment},
  booktitle = {Tools and Algorithms for the Construction and Analysis of Systems},
  author    = {Das, Ankush and Hoffmann, Jan},
  editor    = {Legay, Axel and Margaria, Tiziana},
  year      = {2017},
  pages     = {190--207},
  publisher = {{Springer Berlin Heidelberg}},
  address   = {{Berlin}},
  isbn      = {978-3-662-54577-5}
}


@inproceedings{Das2018a,
  title     = {Work {{Analysis}} with {{Resource-Aware Session Types}}},
  booktitle = {Proc. 33rd {{Annual ACM}}/{{IEEE Symposium}} on {{Logic}} in {{Computer Science}}},
  author    = {Das, Ankush and Hoffmann, Jan and Pfenning, Frank},
  year      = {2018},
  month     = jul,
  pages     = {305--314},
  publisher = {ACM},
  address   = {{New York, NY, USA}},
  doi       = {10.1145/3209108.3209146},
  isbn      = {978-1-4503-5583-4}
}

@article{Demetrescu2003,
  author  = {Demetrescu, Camil and Finocchi, Irene and Italiano, Giuseppe F.},
  title   = {Algorithm Engineering, Algorithmics Column},
  year    = {2003},
  journal = {Bull. EATCS},
  volume  = {79},
  pages   = {48--63}
}

@inproceedings{Demontie2015,
  title     = {Automatic {{Inference}} of {{Loop Complexity Through Polynomial Interpolation}}},
  booktitle = {Proc. 19th Brazilian Symposium on Programming Languages},
  author    = {Demonti{\^e}, Francisco and Cezar, Junio and Bigonha, Mariza and Campos, Frederico and Magno Quint{\~a}o Pereira, Fernando},
  editor    = {Pardo, Alberto and Swierstra, S. Doaitse},
  year      = {2015},
  series    = {Lecture {{Notes}} in {{Computer Science}}},
  volume    = {9325},
  pages     = {1--15},
  publisher = {{Springer}},
  address   = {{Cham}},
  doi       = {10.1007/978-3-319-24012-1\_1},
  isbn      = {978-3-319-24012-1}
}

@incollection{Giesl2022,
  title     = {Improving {{Automatic Complexity Analysis}} of~{{Integer Programs}}},
  booktitle = {The {{Logic}} of {{Software}}. {{A Tasting Menu}} of {{Formal Methods}}: {{Essays Dedicated}} to {{Reiner H\"ahnle}} on the {{Occasion}} of {{His}} 60th {{Birthday}}},
  author    = {Giesl, J{\"u}rgen and Lommen, Nils and Hark, Marcel and Meyer, Fabian},
  editor    = {Ahrendt, Wolfgang and Beckert, Bernhard and Bubel, Richard and Johnsen, Einar Broch},
  year      = {2022},
  series    = {Lecture {{Notes}} in {{Computer Science}}},
  volume    = {13360},
  pages     = {193--228},
  publisher = {{Springer}},
  address   = {{Cham}},
  doi       = {10.1007/978-3-031-08166-8_10},
  isbn      = {978-3-031-08166-8}
}

@article{Gil2017,
  title     = {Open Challenges for Probabilistic Measurement-Based Worst-Case Execution Time},
  author    = {Gil, Samuel Jim{\'e}nez and Bate, Iain and Lima, George and Santinelli, Luca and Gogonel, Adriana and {Cucu-Grosjean}, Liliana},
  year      = {2017},
  journal   = {IEEE Embedded Systems Letters},
  volume    = {9},
  number    = {3},
  pages     = {69--72},
  publisher = {{IEEE}}
}

@inproceedings{Goldsmith2007,
  title     = {Measuring Empirical Computational Complexity},
  booktitle = {Proc. the 6th Joint Meeting of the {{European}} Software Engineering Conference and the {{ACM SIGSOFT}} Symposium on {{The}} Foundations of Software Engineering},
  author    = {Goldsmith, Simon F. and Aiken, Alex S. and Wilkerson, Daniel S.},
  year      = {2007},
  month     = sep,
  fseries   = {{{ESEC-FSE}} '07},
  pages     = {395--404},
  publisher = {{ACM}},
  address   = {{New York, NY, USA}},
  doi       = {10.1145/1287624.1287681},
  isbn      = {978-1-59593-811-4}
}

@inproceedings{Griffin2010,
  title     = {Realism in Statistical Analysis of Worst Case Execution Times},
  booktitle = {10th International Workshop on Worst-Case Execution Time Analysis},
  author    = {Griffin, David and Burns, Alan},
  series    = {{{OpenAccess}} Series in Informatics ({{OASIcs}})},
  volume    = {15},
  pages     = {44--53},
  year      = {2010},
  publisher = {{Schloss Dagstuhl\textendash Leibniz-Zentrum fuer Informatik}},
  address   = {Wadern},
  doi       = {10.4230/OASIcs.WCET.2010.44}
}

@inproceedings{Grosen2023,
  title     = {Automatic {{Amortized Resource Analysis}} with {{Regular Recursive Types}}},
  booktitle = {Proc. 38th {{Annual ACM}}/{{IEEE Symposium}} on {{Logic}} in {{Computer Science}}},
  author    = {Grosen, Jessie and Kahn, David M. and Hoffmann, Jan},
  year      = {2023},
  month     = jun,
  pages     = {1--14},
  publisher = {{IEEE}},
  address   = {New York, NY, USA},
  doi       = {10.1109/LICS56636.2023.10175720}
}

@inproceedings{Gulwani2011,
  title     = {Automating String Processing in Spreadsheets Using Input-Output Examples},
  booktitle = {Proc. 38th Annual {{ACM SIGPLAN-SIGACT}} Symposium on {{Principles}} of Programming Languages},
  author    = {Gulwani, Sumit},
  year      = {2011},
  month     = jan,
  fseries   = {{{POPL}} '11},
  pages     = {317--330},
  publisher = {ACM},
  address   = {{New York, NY, USA}},
  doi       = {10.1145/1926385.1926423}
}

@article{Handley2019,
  title     = {Liquidate Your Assets: Reasoning about Resource Usage in Liquid {{Haskell}}},
  author    = {Handley, Martin A. T. and Vazou, Niki and Hutton, Graham},
  year      = {2019},
  month     = dec,
  journal   = {Proc. ACM Program. Lang.},
  volume    = {4},
  number    = {POPL},
  pubsliher = {ACM},
  address   = {{New York, NY, USA}},
  articleno = {24},
  numpages  = {27},
  doi       = {10.1145/3371092}
}

@phdthesis{Hoffmann2011a,
  title  = {Types with Potential: Polynomial Resource Bounds via Automatic Amortized Analysis},
  author = {Hoffmann, Jan},
  year   = {2011},
  month  = oct,
  url    = {https://edoc.ub.uni-muenchen.de/13955/},
  school = {Ludwig-Maximilians-Universit\"at M\"unchen}
}

@inproceedings{Hoffmann2011,
  title     = {Multivariate Amortized Resource Analysis},
  author    = {Hoffmann, Jan and Aehlig, Klaus and Hofmann, Martin},
  booktitle = {Proc. 38th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  year      = {2011},
  month     = jan,
  numpages  = {14},
  pages     = {357--370},
  doi       = {10.1145/1926385.1926427},
  publisher = {ACM},
  address   = {{New York, NY, USA}}
}

@inproceedings{Hoffmann2012,
  title     = {Resource {{Aware ML}}},
  booktitle = {Proc. 24 International Conference on Computer {{Aided Verification}}},
  author    = {Hoffmann, Jan and Aehlig, Klaus and Hofmann, Martin},
  editor    = {Madhusudan, P. and Seshia, Sanjit A.},
  year      = {2012},
  series    = {Lecture {{Notes}} in {{Computer Science}}},
  pages     = {781--786},
  publisher = {{Springer}},
  address   = {{Berlin}},
  doi       = {10.1007/978-3-642-31424-7_64}
}

@inproceedings{Hoffmann2017,
  title     = {Towards Automatic Resource Bound Analysis for {{OCaml}}},
  booktitle = {Proc. 44th {{ACM SIGPLAN Symposium}} on {{Principles}} of {{Programming Languages}}},
  author    = {Hoffmann, Jan and Das, Ankush and Weng, Shu-Chun},
  year      = {2017},
  month     = jan,
  pages     = {359--373},
  publisher = {{ACM}},
  address   = {{New York, NY, USA}},
  doi       = {10.1145/3009837.3009842}
}

@inproceedings{Hoffmann2010,
  title     = {Amortized {{Resource Analysis}} with {{Polymorphic Recursion}} and {{Partial Big-Step Operational Semantics}}},
  booktitle = {Proc. 8th Asian Symposium on Programming Languages and Systems},
  author    = {Hoffmann, Jan and Hofmann, Martin},
  editor    = {Ueda, Kazunori},
  year      = {2010},
  series    = {Lecture {{Notes}} in {{Computer Science}}},
  volume    = {6461},
  pages     = {172--187},
  publisher = {{Springer}},
  address   = {{Berlin}},
  doi       = {10.1007/978-3-642-17164-2_13},
  isbn      = {978-3-642-17164-2}
}

@inproceedings{Hoffmann2010a,
  title     = {Amortized {{Resource Analysis}} with {{Polynomial Potential}}},
  booktitle = {Proc. 19th European Symposium on Programming Languages and Systems},
  author    = {Hoffmann, Jan and Hofmann, Martin},
  editor    = {Gordon, Andrew D.},
  year      = {2010},
  series    = {Lecture {{Notes}} in {{Computer Science}}},
  volume    = {6012},
  pages     = {287--306},
  publisher = {{Springer}},
  address   = {{Berlin}},
  doi       = {10.1007/978-3-642-11957-6_16}
}

@article{Hoffmann2022,
  title     = {Two Decades of Automatic Amortized Resource Analysis},
  author    = {Hoffmann, Jan and Jost, Steffen},
  year      = {2022},
  month     = jun,
  journal   = {Mathematical Structures in Computer Science},
  volume    = {32},
  number    = {6},
  pages     = {729--759},
  publisher = {{Cambridge University Press}},
  issn      = {0960-1295, 1469-8072},
  doi       = {10.1017/S0960129521000487},
  url       = {https://www.cambridge.org/core/journals/mathematical-structures-in-computer-science/article/two-decades-of-automatic-amortized-resource-analysis/9A47A8663CD8A7147E2F17865C368094}
}

@inproceedings{Hoffmann2015,
  title     = {Automatic {{Static Cost Analysis}} for {{Parallel Programs}}},
  booktitle = {Proc. 24th European Symposium on Programming Languages and Systems},
  author    = {Hoffmann, Jan and Shao, Zhong},
  editor    = {Vitek, Jan},
  year      = {2015},
  series    = {Lecture {{Notes}} in {{Computer Science}}},
  volume    = {9032},
  pages     = {132--157},
  publisher = {{Springer}},
  address   = {{Berlin}},
  doi       = {10.1007/978-3-662-46669-8_6},
  isbn      = {978-3-662-46669-8}
}

@inproceedings{Hofmann2003,
  title     = {Static Prediction of Heap Space Usage for First-Order Functional Programs},
  booktitle = {Proc. 30th {{ACM SIGPLAN-SIGACT}} Symposium on Principles of Programming Languages},
  author    = {Hofmann, Martin and Jost, Steffen},
  year      = {2003},
  pages     = {185--197},
  publisher = {{ACM}},
  address   = {{New York, NY, USA}},
  doi       = {10.1145/604131.604148}
}

@misc{Hofmann2018,
  title        = {Analysis of Logarithmic Amortised Complexity},
  author       = {Hofmann, Martin and Moser, Georg},
  year         = {2018},
  month        = jul,
  number       = {arXiv:1807.08242},
  eprint       = {1807.08242},
  primaryclass = {cs},
  publisher    = {{arXiv}},
  doi          = {10.48550/arXiv.1807.08242}
}

@article{Hofmann2022,
  title     = {Type-Based Analysis of Logarithmic Amortised Complexity},
  author    = {Hofmann, Martin and Leutgeb, Lorenz and Obwaller, David and Moser, Georg and Zuleger, Florian},
  year      = {2022},
  month     = jun,
  journal   = {Mathematical Structures in Computer Science},
  volume    = {32},
  number    = {6},
  pages     = {794--826},
  publisher = {{Cambridge University Press}},
  issn      = {0960-1295, 1469-8072},
  doi       = {10.1017/S0960129521000232}
}

@inproceedings{Hofmann2014,
  title     = {Amortised Resource Analysis and Typed Polynomial Interpretations},
  booktitle = {Rewriting and Typed Lambda Calculi},
  author    = {Hofmann, Martin and Moser, Georg},
  series    = {Lecture Notes in Computer Science},
  volume    = {8560},
  year      = {2014},
  pages     = {272--286},
  publisher = {Springer},
  address   = {Heidelberg},
  doi       = {10.1007/978-3-319-08918-8_19}
}

@inproceedings{Huang2010,
  title     = {Predicting Execution Time of Computer Programs Using Sparse Polynomial Regression},
  booktitle = {Advances in Neural Information Processing Systems},
  author    = {Huang, Ling and Jia, Jinzhu and Yu, Bin and Chun, Byung-Gon and Maniatis, Petros and Naik, Mayur},
  volume    = {23},
  year      = {2010},
  pages     = {883--891},
  publisher = {{Curran Associates Inc.}},
  address   = {{Red Hook, NY, USA}}
}

@article{Ishimwe2021,
  title      = {Dynaplex: {{Analyzing}} Program Complexity Using Dynamically Inferred Recurrence Relations},
  author     = {Ishimwe, Didier and Nguyen, KimHao and Nguyen, ThanhVu},
  year       = {2021},
  month      = oct,
  journal    = {Proc. ACM Program. Lang.},
  volume     = {5},
  number     = {OOPSLA},
  publisher  = {{ACM}},
  address    = {{New York, NY, USA}},
  doi        = {10.1145/3485515},
  articleno  = {138},
  numpages   = {23},
  issue_date = {October 2021}
}

@inproceedings{Johnson1999,
  title     = {A Theoretician's Guide to the Experimental Analysis of Algorithms},
  booktitle = {Data Structures, Near Neighbor Searches, and Methodology: Fifth and Sixth DIMACS Implementation Challenges},
  author    = {Johnson, David S.},
  editor    = {Goldwasser, Michael H. and Johnson, David S. and McGeoch, Catherine C.},
  year      = {1999},
  series    = {{{DIMACS}} Series in Discrete Mathematics and Theoretical Computer Science},
  volume    = {59},
  pages     = {215--250},
  publisher = {{DIMACS/AMS}},
  address   = {Piscataway, NJ, USA},
  doi       = {10.1090/dimacs/059/11},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Jost2010a,
  title   = {Static Determination of Quantitative Resource Usage for Higher-Order Programs},
  author  = {Jost, Steffen and Hammond, Kevin and Loidl, Hans-Wolfgang and Hofmann, Martin},
  year    = {2010},
  month   = jan,
  journal = {Proc. 37th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  volume  = {45},
  number  = {1},
  pages   = {223--236},
  issn    = {0362-1340},
  doi     = {10.1145/1706299.1706327}
}

@article{Kavvos2019,
  title      = {Recurrence Extraction for Functional Programs through Call-by-Push-Value},
  author     = {Kavvos, G. A. and Morehouse, Edward and Licata, Daniel R. and Danner, Norman},
  year       = {2019},
  month      = dec,
  journal    = {Proc. ACM Program. Lang.},
  volume     = {4},
  number     = {POPL},
  publisher  = {{ACM}},
  address    = {{New York, NY, USA}},
  doi        = {10.1145/3371083},
  articleno  = {15},
  numpages   = {31},
  issue_date = {January 2020}
}

@article{Kincaid2017,
  title      = {Non-Linear Reasoning for Invariant Synthesis},
  author     = {Kincaid, Zachary and Cyphert, John and Breck, Jason and Reps, Thomas},
  year       = {2017},
  month      = dec,
  journal    = {Proc. ACM Program. Lang.},
  volume     = {2},
  number     = {POPL},
  publisher  = {{ACM}},
  address    = {{New York, NY, USA}},
  doi        = {10.1145/3158142},
  articleno  = {54},
  numpages   = {33},
  issue_date = {January 2018}
}

@article{Knoth2020,
  title    = {Liquid Resource Types},
  author   = {Knoth, Tristan and Wang, Di and Reynolds, Adam and Hoffmann, Jan and Polikarpova, Nadia},
  year     = {2020},
  month    = aug,
  journal  = {Proceedings of the ACM on Programming Languages},
  volume   = {4},
  number   = {ICFP},
  pages    = {106:1--106:29},
  doi      = {10.1145/3408988},
  urldate  = {2022-07-08},
  abstract = {This article presents liquid resource types, a technique for automatically verifying the resource consumption of functional programs. Existing resource analysis techniques trade automation for flexibility -- automated techniques are restricted to relatively constrained families of resource bounds, while more expressive proof techniques admitting value-dependent bounds rely on handwritten proofs. Liquid resource types combine the best of these approaches, using logical refinements to automatically prove precise bounds on a program's resource consumption. The type system augments refinement types with potential annotations to conduct an amortized resource analysis. Importantly, users can annotate data structure declarations to indicate how potential is allocated within the type, allowing the system to express bounds with polynomials and exponentials, as well as more precise expressions depending on program values. We prove the soundness of the type system, provide a library of flexible and reusable data structures for conducting resource analysis, and use our prototype implementation to automatically verify resource bounds that previously required a manual proof.},
  keywords = {Automated amortized resource analysis,Refinement types}
}

@inproceedings{Kook2022,
  title     = {Sampling with {{Riemannian Hamiltonian Monte Carlo}} in a {{Constrained Space}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  volume    = {35},
  author    = {Kook, Yunbum and Lee, YinTat and Shen, Ruoqi and Vempala, Santosh},
  year      = {2022},
  numpages  = {13},
  fmonth    = oct,
  publisher = {{Curran Associates Inc.}},
  address   = {{Red Hook, NY, USA}}
}

@inproceedings{Lago2011,
  title     = {Linear Dependent Types and Relative Completeness},
  booktitle = {Proc. 26th {{IEEE}} Symposium on Logic in Computer Science},
  author    = {Lago, Ugo Dal and Gaboardi, Marco},
  pages     = {133--142},
  year      = {2011},
  publisher = {IEEE},
  address   = {New York, NY, USA},
  doi       = {10.1109/LICS.2011.22}
}

@inproceedings{Leutgeb2021,
  title     = {{{ATLAS}}: {{Automated Amortised Complexity Analysis}} of {{Self-adjusting Data Structures}}},
  booktitle = {Proc. 33rd International Conference on Computer Aided Verification},
  author    = {Leutgeb, Lorenz and Moser, Georg and Zuleger, Florian},
  pages     = {99--122},
  month     = jul,
  series    = {Lecture Notes in Computer Science},
  volume    = {12760},
  publisher = {{Springer-Verlag}},
  year      = {2021},
  address   = {{Berlin}},
  doi       = {10.1007/978-3-030-81688-9_5}
}

@inproceedings{Lichtman2017,
  title     = {Arrays and {{References}} in {{Resource Aware ML}}},
  booktitle = {Proc. 2nd {{International Conference}} on {{Formal Structures}} for {{Computation}} and {{Deduction}}},
  author    = {Lichtman, Benjamin and Hoffmann, Jan},
  editor    = {Miller, Dale},
  year      = {2017},
  series    = {Leibniz {{International Proceedings}} in {{Informatics}}},
  volume    = {84},
  article   = {26},
  numpages  = {20},
  publisher = {{Schloss Dagstuhl\textendash Leibniz-Zentrum fuer Informatik}},
  address   = {{Dagstuhl, Germany}},
  doi       = {10.4230/LIPIcs.FSCD.2017.26}
}

@inproceedings{Lima2016,
  title     = {Extreme Value Theory for Estimating Task Execution Time Bounds: {{A}} Careful Look},
  booktitle = {Proc. 28th Euromicro Conference on Real-Time Systems},
  author    = {Lima, George and Dias, Dario and Barros, Edna},
  year      = {2016},
  pages     = {200--211},
  doi       = {10.1109/ECRTS.2016.20},
  publisher = {{IEEE}},
  address   = {New York, NY, USA}
}

@article{Lu2011,
  title     = {A New Way About Using Statistical Analysis of Worst-Case Execution Times},
  author    = {Lu, Yue and Nolte, Thomas and Bate, Iain and {Cucu-Grosjean}, Liliana},
  year      = {2011},
  journal   = {ACM SIGBED Review},
  volume    = {8},
  number    = {3},
  pages     = {11--14},
  publisher = {{ACM}},
  address   = {New York, NY, USA},
  doi       = {10.1145/2038617.2038619}
}

@phdthesis{McGeoch1987,
  title   = {Experimental {{Analysis}} of {{Algorithms}}.},
  author  = {McGeoch, Catherine},
  year    = {1987},
  month   = dec,
  chapter = {Technical Reports},
  school  = {Carnegie Mellon University}
}

@incollection{McGeoch2002,
  title     = {Using {{Finite Experiments}} to {{Study Asymptotic Performance}}},
  booktitle = {Experimental {{Algorithmics}}: {{From Algorithm Design}} to {{Robust}} and {{Efficient Software}}},
  author    = {McGeoch, Catherine and Sanders, Peter and Fleischer, Rudolf and Cohen, Paul R. and Precup, Doina},
  editor    = {Fleischer, Rudolf and Moret, Bernard and Schmidt, Erik Meineche},
  year      = {2002},
  series    = {Lecture {{Notes}} in {{Computer Science}}},
  pages     = {93--126},
  publisher = {{Springer}},
  address   = {{Berlin}},
  doi       = {10.1007/3-540-36383-1\_5},
  isbn      = {978-3-540-36383-5}
}

@inproceedings{Mevel2019,
  title     = {Time {{Credits}} and {{Time Receipts}} in {{Iris}}},
  booktitle = {Proc. 28th European Symposium on Programming},
  author    = {M{\'e}vel, Glen and Jourdan, Jacques-Henri and Pottier, Fran{\c c}ois},
  editor    = {Caires, Lu{\'i}s},
  year      = {2019},
  series    = {Lecture {{Notes}} in {{Computer Science}}},
  volume    = {11423},
  pages     = {3--29},
  publisher = {{Springer}},
  address   = {{Cham}},
  doi       = {10.1007/978-3-030-17184-1_1},
  isbn      = {978-3-030-17184-1}
}

@inproceedings{Milutinovic2017,
  title     = {On Uses of Extreme Value Theory Fit for Industrial-Quality {{WCET}} Analysis},
  booktitle = {Proc. 12th {{IEEE}} International Symposium on Industrial Embedded Systems},
  author    = {Milutinovic, Suzana and Mezzetti, Enrico and Abella, Jaume and Vardanega, Tullio and Cazorla, Francisco J.},
  year      = {2017},
  pages     = {1--6},
  publisher = {IEEE},
  address   = {New York, NY, USA},
  doi       = {10.1109/SIES.2017.7993402}
}

@inproceedings{MohaselAfshar2015,
  title     = {Reflection, {{Refraction}}, and {{Hamiltonian Monte Carlo}}},
  author    = {Mohasel Afshar, Hadi and Domke, Justin},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  pages     = {3007--3015},
  year      = {2015},
  volume    = {28},
  publisher = {MIT Press},
  address   = {Cambridge, MA, USA}
}

@article{Moine2023,
  title     = {A {{High-Level Separation Logic}} for {{Heap Space}} under {{Garbage Collection}}},
  author    = {Moine, Alexandre and Chargu{\'e}raud, Arthur and Pottier, Fran{\c c}ois},
  year      = {2023},
  month     = jan,
  journal   = {Proc. ACM Program. Lang.},
  volume    = {7},
  number    = {POPL},
  articleno = {25},
  numpages  = {30},
  doi       = {10.1145/3571218}
}

@inproceedings{Moret1999,
  title     = {Towards a Discipline of Experimental Algorithmics},
  booktitle = {Data Structures, Near Neighbor Searches, and Methodology: Fifth and Sixth DIMACS Implementation Challenges},
  author    = {Moret, Bernard M. E.},
  editor    = {Goldwasser, Michael H. and Johnson, David S. and McGeoch, Catherine C.},
  year      = {1999},
  series    = {{{DIMACS}} Series in Discrete Mathematics and Theoretical Computer Science},
  volume    = {59},
  pages     = {197--213},
  publisher = {{DIMACS/AMS}},
  address   = {Piscataway, NJ, USA},
  doi       = {10.1090/dimacs/059/10},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Moser2020,
  title     = {Automated Amortised Resource Analysis for Term Rewrite Systems},
  author    = {Moser, Georg and Schneckenreither, Manuel},
  year      = {2020},
  month     = jan,
  journal   = {Science of Computer Programming},
  volume    = {185},
  articleno = {102306},
  numpages  = {18},
  issn      = {0167-6423},
  publisher = {Elsevier},
  doi       = {10.1016/j.scico.2019.102306}
}

@inproceedings{Ngo2018,
  title     = {Bounded Expectations: Resource Analysis for Probabilistic Programs},
  booktitle = {Proc. 39th {{ACM SIGPLAN Conference}} on {{Programming Language Design}} and {{Implementation}}},
  author    = {Ngo, Van Chan and Carbonneaux, Quentin and Hoffmann, Jan},
  year      = {2018},
  month     = jun,
  pages     = {496--512},
  publisher = {{ACM}},
  address   = {{New York, NY, USA}},
  doi       = {10.1145/3192366.3192394}
}

@article{Nipkow2019,
  title   = {Amortized {{Complexity Verified}}},
  author  = {Nipkow, Tobias and Brinkop, Hauke},
  year    = {2019},
  month   = mar,
  journal = {Journal of Automated Reasoning},
  volume  = {62},
  number  = {3},
  pages   = {367--391},
  doi     = {10.1007/s10817-018-9459-3}
}

@article{Niu2022,
  title     = {A Cost-Aware Logical Framework},
  author    = {Niu, Yue and Sterling, Jonathan and Grodin, Harrison and Harper, Robert},
  year      = {2022},
  month     = jan,
  journal   = {Proc. ACM Program. Lang.},
  volume    = {6},
  number    = {POPL},
  aritcleno = {9},
  numpages  = {31},
  pages     = {1--31},
  doi       = {10.1145/3498670}
}

@article{Qin2022,
  title   = {Algorithmic {{Profiling}} for {{Real-World Complexity Problems}}},
  author  = {Qin, Boqin and Tu, Tengfei and Liu, Ziheng and Yu, Tingting and Song, Linhai},
  year    = {2022},
  month   = jul,
  journal = {IEEE Trans. Softw. Eng.},
  volume  = {48},
  number  = {7},
  pages   = {2680--2694},
  issn    = {1939-3520},
  doi     = {10.1109/TSE.2021.3067652}
}

@article{Reghenzani2020,
  title     = {Dealing with {{Uncertainty}} in {{pWCET Estimations}}},
  author    = {Reghenzani, Federico and Santinelli, Luca and Fornaciari, William},
  year      = {2020},
  month     = sep,
  journal   = {ACM Transactions on Embedded Computing Systems},
  volume    = {19},
  number    = {5},
  articleno = {33},
  numpages  = {23},
  issn      = {1539-9087},
  doi       = {10.1145/3396234},
  urldate   = {2023-05-17},
  abstract  = {The problem of estimating a tight and safe Worst-Case Execution Time (WCET), needed for certification in safety-critical environment, is a challenging problem for modern embedded systems. A possible solution proposed in past years is to exploit statistical tools to obtain a probability distribution of the WCET. These probabilistic real-time analyses for WCET are, however, subject to errors, even when all the applicability hypotheses are satisfied and verified. This is caused by the uncertainties of the probabilistic-WCET distribution estimator. This article aims at improving the measurement-based probabilistic timing analysis approach providing some techniques to analyze and deal with such uncertainties. The so-called region of acceptance model based on state-of-the-art statistical test procedures is defined over the distribution space parameters. From this model, a set of strategies is derived and discussed to provide the methodology to deal with the trade-off safety/tightness of the WCET estimation. These techniques are then tested over real datasets, including industrial safety-critical applications, to show the increased value of using the proposed approach in probabilistic WCET analyses.},
  keywords  = {embedded systems,probabilistic real-time,pWCET}
}

@misc{Rizelli2024,
  title         = {Empirical {Bayes} in {Bayesian} Learning: Understanding a Common Practice},
  author        = {Rizzelli, Stefano and Rousseau, Judith and Petrone, Sonia},
  year          = {2024},
  month         = feb,
  number        = {arXiv:2402.19036},
  eprint        = {2402.19036},
  primaryclass  = {math},
  publisher     = {arXiv},
  archiveprefix = {arxiv}
}

@inproceedings{Rogora2020,
  title     = {Analyzing System Performance with Probabilistic Performance Annotations},
  booktitle = {Proc. 15th European Conference on {{Computer Systems}}},
  author    = {Rogora, Daniele and Carzaniga, Antonio and Diwan, Amer and Hauswirth, Matthias and Soul{\'e}, Robert},
  year      = {2020},
  month     = apr,
  pages     = {1--14},
  publisher = {{ACM}},
  address   = {{New York, NY, USA}},
  doi       = {10.1145/3342195.3387554}
}

@inproceedings{Sanders2001,
  title     = {Asymptotic {{Complexity}} from {{Experiments}}? {{A Case Study}} for {{Randomized Algorithms}}},
  author    = {Sanders, Peter and Fleischer, Rudolf},
  booktitle = {International Workshop on Algorithm {{Engineering}}},
  editor    = {N{\"a}her, Stefan and Wagner, Dorothea},
  year      = {2001},
  series    = {Lecture {{Notes}} in {{Computer Science}}},
  volume    = {1982},
  pages     = {135--146},
  publisher = {{Springer}},
  address   = {{Berlin}},
  doi       = {10.1007/3-540-44691-5\_12}
}

@inproceedings{Sinn2014,
  title     = {A {{Simple}} and {{Scalable Static Analysis}} for {{Bound Analysis}} and {{Amortized Complexity Analysis}}},
  booktitle = {Proc. 26th International Conference on Computer Aided Verification},
  author    = {Sinn, Moritz and Zuleger, Florian and Veith, Helmut},
  editor    = {Biere, Armin and Bloem, Roderick},
  year      = {2014},
  series    = {Lecture {{Notes}} in {{Computer Science}}},
  volume    = {8559},
  pages     = {745--761},
  publisher = {{Springer}},
  address   = {{Cham}},
  doi       = {10.1007/978-3-319-08867-9_50}
}

@inproceedings{Sleator1983,
  title     = {Self-Adjusting Binary Trees},
  booktitle = {Proc. 15th Annual {{ACM}} Symposium on {{Theory}} of Computing},
  author    = {Sleator, Daniel D. and Tarjan, Robert E.},
  year      = {1983},
  month     = dec,
  pages     = {235--245},
  publisher = {{ACM}},
  address   = {{New York, NY, USA}},
  doi       = {10.1145/800061.808752},
  urldate   = {2023-09-28},
  abstract  = {We use the idea of self-adjusting trees to create new, simple data structures for priority queues (which we call heaps) and search trees. Unlike other efficient implementations of these data structures, self-adjusting trees have no balance condition. Instead, whenever the tree is accessed, certain adjustments take place. (In the case of heaps, the adjustment is a sequence of exchanges of children, in the case of search trees the adjustment is a sequence of rotations.) Self-adjusting trees are efficient in an amortized sense: any particular operation may be slow but any sequence of operations must be fast. Self-adjusting trees have two advantages over the corresponding balanced trees in both applications. First, they are simpler to implement because there are fewer cases in the algorithms. Second, they are more storage-efficient because no balance information needs to be stored. Furthermore, a self-adjusting search tree has the remarkable property that its running time (for any sufficiently long sequence of search operations) is within a constant factor of the running time for the same set of searches on any fixed binary tree. It follows that a self-adjusting tree is (up to a constant factor) as fast as the optimal fixed tree for a particular probability distribution of search requests, even though the distribution is unknown.},
  isbn      = {978-0-89791-099-6}
}

@article{Plotkin1973,
  title     = {LCF Considered as a Programming Language},
  author    = {Plotkin, Gordon D.},
  journal   = {Theoretical Computer Science},
  volume    = {5},
  number    = {3},
  pages     = {223--255},
  year      = {1977},
  doi       = {10.1016/0304-3975(77)90044-5},
  publisher = {Elsevier},
  address   = {Amsterdam, The Netherlands}
}

@article{Tarjan1985,
  title    = {Amortized Computational Complexity},
  author   = {Tarjan, Robert E.},
  year     = {1985},
  month    = apr,
  journal  = {SIAM Journal on Matrix Analysis and Applications},
  volume   = {6},
  number   = {2},
  pages    = {306--13},
  abstract = {A powerful technique in the complexity analysis of data structures is amortization, or averaging over time. Amortized running time is a realistic but robust complexity measure for which we can obtain surprisingly tight upper and lower bounds on a variety of algorithms. By following the principle of designing algorithms whose amortized complexity is low, we obtain "self-adjusting" data structures that are simple, flexible and efficient. This paper surveys recent work by several researchers on amortized complexity.},
  isbn     = {08954798},
  langid   = {english},
  keywords = {Mathematics},
  doi      = {10.1137/0606031}
}

@article{Sleator1985,
  title   = {Amortized Efficiency of List Update and Paging Rules},
  author  = {Sleator, Daniel D. and Tarjan, Robert E.},
  year    = {1985},
  month   = feb,
  journal = {Communications of the ACM},
  volume  = {28},
  number  = {2},
  pages   = {202--208},
  issn    = {0001-0782},
  doi     = {10.1145/2786.2793}
}

@phdthesis{Vasconcelos2008,
  title  = {Space Cost Analysis Using Sized Types},
  author = {Vasconcelos, Pedro B.},
  year   = {2008},
  school = {University of St. Andrews}
}

@article{Wang2020,
  title     = {Raising Expectations: Automating Expected Cost Analysis with Types},
  author    = {Wang, Di and Kahn, David M. and Hoffmann, Jan},
  year      = {2020},
  month     = aug,
  journal   = {Proc. ACM Program. Lang.},
  volume    = {4},
  number    = {ICFP},
  aritcleno = {100},
  numpages  = {31},
  doi       = {10.1145/3408992},
  urldate   = {2022-07-08},
  abstract  = {This article presents a type-based analysis for deriving upper bounds on the expected execution cost of probabilistic programs. The analysis is naturally compositional, parametric in the cost model, and supports higher-order functions and inductive data types. The derived bounds are multivariate polynomials that are functions of data structures. Bound inference is enabled by local type rules that reduce type inference to linear constraint solving. The type system is based on the potential method of amortized analysis and extends automatic amortized resource analysis (AARA) for deterministic programs. A main innovation is that bounds can contain symbolic probabilities, which may appear in data structures and function arguments. Another contribution is a novel soundness proof that establishes the correctness of the derived bounds with respect to a distribution-based operational cost semantics that also includes nontrivial diverging behavior. For cost models like time, derived bounds imply termination with probability one. To highlight the novel ideas, the presentation focuses on linear potential and a core language. However, the analysis is implemented as an extension of Resource Aware ML and supports polynomial bounds and user defined data structures. The effectiveness of the technique is evaluated by analyzing the sample complexity of discrete distributions and with a novel average-case estimation for deterministic programs that combines expected cost analysis with statistical methods.},
  keywords  = {analysis of probabilistic programs,expected execution cost,resource-aware type system}
}

@article{Wegbreit1975,
  title    = {Mechanical Program Analysis},
  author   = {Wegbreit, Ben},
  year     = {1975},
  month    = sep,
  journal  = {Communications of the ACM},
  volume   = {18},
  number   = {9},
  pages    = {528--539},
  issn     = {0001-0782},
  doi      = {10.1145/361002.361016},
  urldate  = {2022-07-08},
  abstract = {One means of analyzing program performance is by deriving closed-form expressions for their execution behavior. This paper discusses the mechanization of such analysis, and describes a system, Metric, which is able to analyze simple Lisp programs and produce, for example, closed-form expressions for their running time expressed in terms of size of input. This paper presents the reasons for mechanizing program analysis, describes the operation of Metric, explains its implementation, and discusses its limitations.},
  keywords = {algebraic manipulation,analysis of algorithms,analysis of programs,difference equations,execution behavior,execution time,generating functions,Lisp,list processing,performance analysis,programming languages}
}

@article{Wilhelm2008,
  title     = {The Worst-Case Execution-Time Problem\textemdash Overview of Methods and Survey of Tools},
  author    = {Wilhelm, Reinhard and others},
  year      = {2008},
  journal   = {ACM Transactions on Embedded Computing Systems},
  month     = may,
  volume    = {7},
  number    = {3},
  articleno = {36},
  numpages  = {53},
  issn      = {1539-9087},
  doi       = {10.1145/1347375.1347389}
}

@inproceedings{Zaparanuks2012,
  title     = {Algorithmic Profiling},
  booktitle = {Proc. 33rd {{ACM SIGPLAN}} Conference on Programming Language Design and Implementation},
  author    = {Zaparanuks, Dmitrijs and Hauswirth, Matthias},
  year      = {2012},
  pages     = {67--76},
  publisher = {ACM},
  address   = {New York, NY, USA},
  doi       = {10.1145/2254064.2254074}
}

@inproceedings{Zuleger2011,
  title     = {Bound {{Analysis}} of {{Imperative Programs}} with the {{Size-Change Abstraction}}},
  booktitle = {Proc. 18th International Static Analysis Symposium},
  author    = {Zuleger, Florian and Gulwani, Sumit and Sinn, Moritz and Veith, Helmut},
  editor    = {Yahav, Eran},
  year      = {2011},
  series    = {Lecture {{Notes}} in {{Computer Science}}},
  volume    = {6887},
  pages     = {280--297},
  publisher = {{Springer}},
  address   = {{Berlin}},
  doi       = {10.1007/978-3-642-23702-7_22}
}

@inproceedings{Danielsson2008,
  title     = {Lightweight Semiformal Time Complexity Analysis for Purely Functional Data Structures},
  booktitle = {Proceedings of the 35th Annual {{ACM SIGPLAN-SIGACT}} Symposium on Principles of Programming Languages},
  author    = {Danielsson, Nils Anders},
  year      = {2008},
  series    = {{{POPL}} '08},
  pages     = {133--144},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/1328438.1328457},
  isbn      = {978-1-59593-689-9},
  keywords  = {amortised time complexity,dependent types,lazy evaluation,purely functional data structures}
}

@inproceedings{Grobauer2001,
  title     = {Cost Recurrences for {{DML}} Programs},
  booktitle = {Proc. 6th {{ACM SIGPLAN}} International Conference on Functional Programming},
  author    = {Grobauer, Bernd},
  year      = {2001},
  pages     = {253--264},
  publisher = {{ACM}},
  address   = {{New York, NY, USA}},
  doi       = {10.1145/507635.507666},
  isbn      = {1-58113-415-0}
}

@inproceedings{Gulwani2009,
  title     = {{{SPEED}}: {{Precise}} and Efficient Static Estimation of Program Computational Complexity},
  booktitle = {Proc. 36th Annual {{ACM SIGPLAN-SIGACT}} Symposium on Principles of Programming Languages},
  author    = {Gulwani, Sumit and Mehra, Krishna K. and Chilimbi, Trishul},
  year      = {2009},
  pages     = {127--139},
  publisher = {{ACM}},
  address   = {{New York, NY, USA}},
  doi       = {10.1145/1480881.1480898},
  abstract  = {This paper describes an inter-procedural technique for computing symbolic bounds on the number of statements a procedure executes in terms of its scalar inputs and user-defined quantitative functions of input data-structures. Such computational complexity bounds for even simple programs are usually disjunctive, non-linear, and involve numerical properties of heaps. We address the challenges of generating these bounds using two novel ideas.We introduce a proof methodology based on multiple counter instrumentation (each counter can be initialized and incremented at potentially multiple program locations) that allows a given linear invariant generation tool to compute linear bounds individually on these counter variables. The bounds on these counters are then composed together to generate total bounds that are non-linear and disjunctive. We also give an algorithm for automating this proof methodology. Our algorithm generates complexity bounds that are usually precise not only in terms of the computational complexity, but also in terms of the constant factors.Next, we introduce the notion of user-defined quantitative functions that can be associated with abstract data-structures, e.g., length of a list, height of a tree, etc. We show how to compute bounds in terms of these quantitative functions using a linear invariant generation tool that has support for handling uninterpreted functions. We show application of this methodology to commonly used data-structures (namely lists, list of lists, trees, bit-vectors) using examples from Microsoft product code. We observe that a few quantitative functions for each data-structure are usually sufficient to allow generation of symbolic complexity bounds of a variety of loops that iterate over these data-structures, and that it is straightforward to define these quantitative functions.The combination of these techniques enables generation of precise computational complexity bounds for real-world examples (drawn from Microsoft product code and C++ STL library code) for some of which it is non-trivial to even prove termination. Such automatically generated bounds are very useful for early detection of egregious performance problems in large modular codebases that are constantly being changed by multiple developers who make heavy use of code written by others without a good understanding of their implementation complexity.},
  isbn      = {978-1-60558-379-2},
  keywords  = {counter instrumentation,quantitative functions,symbolic complexity bounds,termination analysis}
}

@inproceedings{RaML,
  author    = {Hoffmann, Jan and Aehlig, Klaus and Hofmann, Martin},
  editor    = {Madhusudan, P. and Seshia, Sanjit A.},
  title     = {Resource Aware {ML}},
  booktitle = {Proc. 24 International Conference on Computer Aided Verification},
  series    = {Lecture Notes in Computer Science},
  volume    = {7358},
  year      = {2012},
  pages     = {781--786},
  publisher = {Springer},
  address   = {Berlin},
  doi       = {10.1007/978-3-642-31424-7_64}
}


@article{Kahn2021,
  title   = {Automatic Amortized Resource Analysis with the Quantum Physicist's Method},
  author  = {Kahn, David M. and Hoffmann, Jan},
  year    = {2021},
  month   = aug,
  journal = {Proceedings of the ACM on Programming Languages},
  volume  = {5},
  number  = {ICFP},
  pages   = {76:1--76:29},
  doi     = {10.1145/3473581},
  url     = {https://doi.org/10.1145/3473581}
}

@inproceedings{Kahn2020,
  title     = {Exponential {{Automatic Amortized Resource Analysis}}},
  booktitle = {Proc. 23rd International Conference on Foundations of {{Software Science}} and {{Computation Structures}}},
  author    = {Kahn, David M. and Hoffmann, Jan},
  editor    = {{Goubault-Larrecq}, Jean and K{\"o}nig, Barbara},
  year      = {2020},
  series    = {Lecture {{Notes}} in {{Computer Science}}},
  volume    = {12077},
  pages     = {359--380},
  publisher = {{Springer}},
  address   = {{Cham}},
  doi       = {10.1007/978-3-030-45231-5_19},
  abstract  = {Automatic amortized resource analysis (AARA) is a type-based technique for inferring concrete (non-asymptotic) bounds on a program's resource usage. Existing work on AARA has focused on bounds that are polynomial in the sizes of the inputs. This paper presents and extension of AARA to exponential bounds that preserves the benefits of the technique, such as compositionality and efficient type inference based on linear constraint solving. A key idea is the use of the Stirling numbers of the second kind as the basis of potential functions, which play the same role as the binomial coefficients in polynomial AARA. To formalize the similarities with the existing analyses, the paper presents a general methodology for AARA that is instantiated to the polynomial version, the exponential version, and a combined system with potential functions that are formed by products of Stirling numbers and binomial coefficients. The soundness of exponential AARA is proved with respect to an operational cost semantics and the analysis of representative example programs demonstrates the effectiveness of the new analysis.},
  isbn      = {978-3-030-45231-5},
  langid    = {english},
  keywords  = {Amortized analysis,Exponential,Functional programming,Quantitative analysis,Resource consumption,Stirling numbers}
}

@inproceedings{Leutgeb2022,
  title     = {Automated {{Expected Amortised Cost Analysis}} of~{{Probabilistic Data Structures}}},
  booktitle = {Proc. 34th International Conference on Computer Aided Verification},
  author    = {Leutgeb, Lorenz and Moser, Georg and Zuleger, Florian},
  editor    = {Shoham, Sharon and Vizel, Yakir},
  year      = {2022},
  series    = {Lecture {{Notes}} in {{Computer Science}}},
  volume    = {13372},
  pages     = {70--91},
  publisher = {{Springer}},
  address   = {{Cham}},
  doi       = {10.1007/978-3-031-13188-2_4}
}

@misc{Pham2023,
  author = {Pham, Long and Saad, Feras and Hoffmann, Jan},
  title  = {Hybrid Resource-Aware ML},
  year   = {2023},
  doi    = {10.5281/zenodo.10937074}
}

@article{Rajani2021,
  title    = {A Unifying Type-Theory for Higher-Order (Amortized) Cost Analysis},
  author   = {Rajani, Vineet and Gaboardi, Marco and Garg, Deepak and Hoffmann, Jan},
  year     = {2021},
  month    = jan,
  journal  = {Proceedings of the ACM on Programming Languages},
  volume   = {5},
  number   = {POPL},
  pages    = {27:1--27:28},
  doi      = {10.1145/3434308},
  url      = {https://doi.org/10.1145/3434308},
  urldate  = {2022-07-08},
  abstract = {This paper presents {$\lambda$}-amor, a new type-theoretic framework for amortized cost analysis of higher-order functional programs and shows that existing type systems for cost analysis can be embedded in it. {$\lambda$}-amor introduces a new modal type for representing potentials \textendash{} costs that have been accounted for, but not yet incurred, which are central to amortized analysis. Additionally, {$\lambda$}-amor relies on standard type-theoretic concepts like affineness, refinement types and an indexed cost monad. {$\lambda$}-amor is proved sound using a rather simple logical relation. We embed two existing type systems for cost analysis in {$\lambda$}-amor showing that, despite its simplicity, {$\lambda$}-amor can simulate cost analysis for different evaluation strategies (call-by-name and call-by-value), in different styles (effect-based and coeffect-based), and with or without amortization. One of the embeddings also implies that {$\lambda$}-amor is relatively complete for all terminating PCF programs.},
  keywords = {amortized cost analysis,relative completeness,type theory}
}

@article{Pham2024,
  author     = {Pham, Long and Saad, Feras A. and Hoffmann, Jan},
  title      = {Robust Resource Bounds with Static Analysis and Bayesian Inference},
  year       = {2024},
  issue_date = {June 2024},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {8},
  number     = {PLDI},
  url        = {https://doi.org/10.1145/3656380},
  doi        = {10.1145/3656380},
  abstract   = {There are two approaches to automatically deriving symbolic worst-case resource bounds for programs: static analysis of the source code and data-driven analysis of cost measurements obtained by running the program. Static resource analysis is usually sound but incomplete. Data-driven analysis can always return a result, but its lack of robustness often leads to unsound results. This paper presents the design, implementation, and empirical evaluation of hybrid resource bound analyses that tightly integrate static analysis and data-driven analysis. The static analysis part builds on automatic amortized resource analysis (AARA), a state-of-the-art type-based resource analysis method that performs cost bound inference using linear optimization. The data-driven part is rooted in novel Bayesian modeling and inference techniques that improve upon previous data-driven analysis methods by reporting an entire probability distribution over likely resource cost bounds. A key innovation is a new type inference system called Hybrid AARA that coherently integrates Bayesian inference into conventional AARA, combining the strengths of both approaches. Hybrid AARA is proven to be statistically sound under standard assumptions on the runtime cost data. An experimental evaluation on a challenging set of benchmarks shows that Hybrid AARA (i) effectively mitigates the incompleteness of purely static resource analysis; and (ii) is more accurate and robust than purely data-driven resource analysis.},
  journal    = {Proc. ACM Program. Lang.},
  month      = jun,
  articleno  = {150},
  numpages   = {26},
  keywords   = {Bayesian inference, data-driven analysis, hybrid analysis, resource analysis, static analysis, worst-case costs}
}

@article{Hoffman2014,
  author     = {Hoffman, Matthew D. and Gelman, Andrew},
  title      = {The No-U-turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo},
  year       = {2014},
  issue_date = {January 2014},
  publisher  = {JMLR.org},
  volume     = {15},
  number     = {1},
  issn       = {1532-4435},
  abstract   = {Hamiltonian Monte Carlo (HMC) is a Markov chain Monte Carlo (MCMC) algorithm that avoids the random walk behavior and sensitivity to correlated parameters that plague many MCMC methods by taking a series of steps informed by first-order gradient information. These features allow it to converge to high-dimensional target distributions much more quickly than simpler methods such as random walk Metropolis or Gibbs sampling. However, HMC's performance is highly sensitive to two user-specified parameters: a step size ε and a desired number of steps L. In particular, if L is too small then the algorithm exhibits undesirable random walk behavior, while if L is too large the algorithm wastes computation. We introduce the No-U-Turn Sampler (NUTS), an extension to HMC that eliminates the need to set a number of steps L. NUTS uses a recursive algorithm to build a set of likely candidate points that spans a wide swath of the target distribution, stopping automatically when it starts to double back and retrace its steps. Empirically, NUTS performs at least as efficiently as (and sometimes more effciently than) a well tuned standard HMC method, without requiring user intervention or costly tuning runs. We also derive a method for adapting the step size parameter ε on the fly based on primal-dual averaging. NUTS can thus be used with no hand-tuning at all, making it suitable for applications such as BUGS-style automatic inference engines that require efficient "turnkey" samplers.},
  journal    = {J. Mach. Learn. Res.},
  month      = {jan},
  pages      = {1593-1623},
  numpages   = {31},
  keywords   = {Bayesian inference, Hamiltonian Monte Carlo, Markov chain Monte Carlo, adaptive Monte Carlo, dual averaging}
}

@article{Kraskov2004,
  title     = {Estimating mutual information},
  author    = {Kraskov, Alexander and St\"ogbauer, Harald and Grassberger, Peter},
  journal   = {Phys. Rev. E},
  volume    = {69},
  issue     = {6},
  pages     = {066138},
  numpages  = {16},
  year      = {2004},
  month     = {Jun},
  publisher = {American Physical Society},
  doi       = {10.1103/PhysRevE.69.066138},
  url       = {https://link.aps.org/doi/10.1103/PhysRevE.69.066138}
}

@article{Kozachenko1987,
  title     = {Sample estimate of the entropy of a random vector},
  author    = {Kozachenko, Lyudmyla F and Leonenko, Nikolai N},
  journal   = {Problemy Peredachi Informatsii},
  volume    = {23},
  number    = {2},
  pages     = {9--16},
  year      = {1987},
  publisher = {Russian Academy of Sciences, Branch of Informatics, Computer Equipment and~…}
}

@book{Cormen2022,
  title     = {Introduction to Algorithms},
  author    = {Cormen, Thomas H. and Leiserson, Charles Eric and Rivest, Ronald L. and Stein, Clifford},
  year      = {2022/2022},
  edition   = {Fourth edition.},
  publisher = {The MIT Press},
  address   = {Cambridge, Massachusetts},
  abstract  = {"A comprehensive update of the leading algorithms text, with new material on matchings in bipartite graphs, online algorithms, machine learning, and other topics.Some books on algorithms are rigorous but incomplete; others cover masses of material but lack rigor. Introduction to Algorithms uniquely combines rigor and comprehensiveness. It covers a broad range of algorithms in depth, yet makes their design and analysis accessible to all levels of readers, with self-contained chapters and algorithms in pseudocode. Since the publication of the first edition, Introduction to Algorithms has become the leading algorithms text in universities worldwide as well as the standard reference for professionals. This fourth edition has been updated throughout, with new chapters on matchings in bipartite graphs, online algorithms, and machine learning, and new material on such topics as solving recurrence equations, hash tables, potential functions, and suffix arrays.Each chapter is relatively self-contained, presenting an algorithm, a design technique, an application area, or a related topic, and can be used as a unit of study. The algorithms are described in English and in a pseudocode designed to be readable by anyone who has done a little programming. The explanations have been kept elementary without sacrificing depth of coverage or mathematical rigor. The fourth edition has 140 new exercises and 22 new problems, and color has been added to improve visual presentations. The writing has been revised throughout, and made clearer, more personal, and gender neutral. The book's website offers supplemental material."-- Provided by publisher.},
  isbn      = {978-0-262-04630-5},
  langid    = {english},
  lccn      = {2021037260},
  keywords  = {Algorithmes,algorithms,Computer algorithms,computer programming,Computer programming,Programmation (Informatique)}
}

@article{Carpenter2017,
  title   = {Stan: A Probabilistic Programming Language},
  volume  = {76},
  url     = {https://www.jstatsoft.org/index.php/jss/article/view/v076i01},
  doi     = {10.18637/jss.v076.i01},
  number  = {1},
  journal = {Journal of Statistical Software},
  author  = {Carpenter, Bob and Gelman, Andrew and Hoffman, Matthew D. and Lee, Daniel and Goodrich, Ben and Betancourt, Michael and Brubaker, Marcus and Guo, Jiqiang and Li, Peter and Riddell, Allen},
  year    = {2017},
  pages   = {1-32}
}

@inproceedings{Breck2020,
  author    = {Breck, Jason and Cyphert, John and Kincaid, Zachary and Reps, Thomas},
  title     = {Templates and recurrences: better together},
  year      = {2020},
  isbn      = {9781450376136},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3385412.3386035},
  doi       = {10.1145/3385412.3386035},
  booktitle = {Proceedings of the 41st ACM SIGPLAN Conference on Programming Language Design and Implementation},
  pages     = {688--702},
  numpages  = {15},
  keywords  = {Recurrence relation, Invariant generation},
  location  = {London, UK},
  series    = {PLDI 2020}
}

@article{Brockschmidt2016,
  author     = {Brockschmidt, Marc and Emmes, Fabian and Falke, Stephan and Fuhs, Carsten and Giesl, J\"{u}rgen},
  title      = {Analyzing Runtime and Size Complexity of Integer Programs},
  year       = {2016},
  issue_date = {October 2016},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {38},
  number     = {4},
  issn       = {0164-0925},
  url        = {https://doi.org/10.1145/2866575},
  doi        = {10.1145/2866575},
  journal    = {ACM Trans. Program. Lang. Syst.},
  month      = {aug},
  articleno  = {13},
  numpages   = {50},
  keywords   = {Runtime complexity, automated complexity analysis, integer programs}
}

@inproceedings{FloresMontoya2014,
  author    = {Flores-Montoya, Antonio
               and H{\"a}hnle, Reiner},
  editor    = {Garrigue, Jacques},
  title     = {Resource Analysis of Complex Programs with Cost Equations},
  booktitle = {Programming Languages and Systems},
  year      = {2014},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {275--295},
  isbn      = {978-3-319-12736-1}
}

@article{Erdos1959,
  author  = {Erd\"{o}s, P. and R\'{e}nyi, A.},
  journal = {Publicationes Mathematicae Debrecen},
  pages   = {290--297},
  title   = {On Random Graphs I},
  volume  = {6},
  year    = {1959},
  doi     = {10.5486/PMD.1959.6.3-4.12}
}

@software{CLP,
  author       = {John Forrest and
                  Stefan Vigerske and
                  Ted Ralphs and
                  John Forrest and
                  Lou Hafer and
                  jpfasano and
                  Haroldo Gambini Santos and
                  Jan-Willem and
                  Matthew Saltzman and
                  Bjarni Kristjansson and
                  h-i-gassmann and
                  Alan King and
                  Arevall and
                  Pierre Bonami and
                  Ruan Luies and
                  Samuel Brito and
                  to-st},
  title        = {coin-or/Clp: Release releases/1.17.9},
  month        = oct,
  year         = 2023,
  organization = {COIN-OR Foundation},
  publisher    = {Zenodo},
  version      = {releases/1.17.9},
  doi          = {10.5281/zenodo.10041272},
  url          = {https://doi.org/10.5281/zenodo.10041272}
}

@inproceedings{Ngo2017,
  title     = {Verifying and {{Synthesizing Constant-Resource Implementations}} with {{Types}}},
  booktitle = {2017 {{IEEE Symposium}} on {{Security}} and {{Privacy}} ({{SP}})},
  author    = {Ngo, Van Chan and {Dehesa-Azuara}, Mario and Fredrikson, Matthew and Hoffmann, Jan},
  year      = {2017},
  month     = may,
  pages     = {710--728},
  publisher = {IEEE Computer Society},
  address   = {New York, NY, USA},
  issn      = {2375-1207},
  doi       = {10.1109/SP.2017.53},
  abstract  = {Side channel attacks have been used to extract critical data such as encryption keys and confidential user data in a variety of adversarial settings. In practice, this threat is addressed by adhering to a constant-time programming discipline, which imposes strict constraints on the way in which programs are written. This introduces an additional hurdle for programmers faced with the already difficult task of writing secure code, highlighting the need for solutions that give the same source-level guarantees while supporting more natural programming models. We propose a novel type system for verifying that programs correctly implement constant-resource behavior. Our type system extends recent work on automatic amortized resource analysis (AARA), a set of techniques that automatically derive provable upper bounds on the resource consumption of programs. We devise new techniques that build on the potential method to achieve compositionality, precision, and automation. A strict global requirement that a program always maintains constant resource usage is too restrictive for most practical applications. It is sufficient to require that the program's resource behavior remain constant with respect to an attacker who is only allowed to observe part of the program's state and behavior. To account for this, our type system incorporates information flow tracking into its resource analysis. This allows our system to certify programs that need to violate the constant-time requirement in certain cases, as long as doing so does not leak confidential information to attackers. We formalize this guarantee by defining a new notion of resource-aware noninterference, and prove that our system enforces it. Finally, we show how our type inference algorithm can be used to synthesize a constant-time implementation from one that cannot be verified as secure, effectively repairing insecure programs automatically. We also show how a second novel AARA system that computes lower bounds on resource usage can be used to derive quantitative bounds on the amount of information that a program leaks through its resource use. We implemented each of these systems in Resource Aware ML, and show that it can be applied to verify constant-time behavior in a number of applications including encryption and decryption routines, database queries, and other resource-aware functionality.},
  keywords  = {Cognition,Encryption,information flow,Language-based security,Programming,resource analysis,Semantics,Standards,static analysis,Syntactics,timing channels}
}

@inproceedings{Huang2022,
  title     = {{{LightPro}}: {{Lightweight}} Probabilistic Workload Prediction Framework for Database-as-a-Service},
  booktitle = {{{IEEE}} International Conference on Web Services, {{ICWS}} 2022, Barcelona, Spain, July 10-16, 2022},
  author    = {Huang, Xiuqi and Cao, Shiyi and Gao, Yuanning and Gao, Xiaofeng and Chen, Guihai},
  editor    = {Ardagna, Claudio Agostino and Atukorala, Nimanthi L. and Benatallah, Boualem and Bouguettaya, Athman and Casati, Fabio and Chang, Carl K. and Chang, Rong N. and Damiani, Ernesto and Gu{\'e}gan, Chirine Ghedira and Ward, Robert and Xhafa, Fatos and Xu, Xiaofei and Zhang, Jia},
  year      = {2022},
  pages     = {160--169},
  publisher = {IEEE},
  address   = {New York, NY, USA},
  doi       = {10.1109/ICWS55610.2022.00036},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  timestamp = {Sun, 06 Oct 2024 21:07:04 +0200}
}

@inproceedings{Roy2011,
  title     = {Efficient {{Autoscaling}} in the {{Cloud Using Predictive Models}} for {{Workload Forecasting}}},
  booktitle = {2011 {{IEEE}} 4th {{International Conference}} on {{Cloud Computing}}},
  author    = {Roy, Nilabja and Dubey, Abhishek and Gokhale, Aniruddha},
  year      = {2011},
  month     = jul,
  pages     = {500--507},
  publisher = {IEEE},
  address   = {New York, NY, USA},
  issn      = {2159-6190},
  doi       = {10.1109/CLOUD.2011.42},
  abstract  = {Large-scale component-based enterprise applications that leverage Cloud resources expect Quality of Service(QoS) guarantees in accordance with service level agreements between the customer and service providers. In the context of Cloud computing, auto scaling mechanisms hold the promise of assuring QoS properties to the applications while simultaneously making efficient use of resources and keeping operational costs low for the service providers. Despite the perceived advantages of auto scaling, realizing the full potential of auto scaling is hard due to multiple challenges stemming from the need to precisely estimate resource usage in the face of significant variability in client workload patterns. This paper makes three contributions to overcome the general lack of effective techniques for workload forecasting and optimal resource allocation. First, it discusses the challenges involved in auto scaling in the cloud. Second, it develops a model-predictive algorithm for workload forecasting that is used for resource auto scaling. Finally, empirical results are provided that demonstrate that resources can be allocated and deal located by our algorithm in a way that satisfies both the application QoS while keeping operational costs low.}
}

@inproceedings{Shen2011,
  title      = {{{CloudScale}}: Elastic Resource Scaling for Multi-Tenant Cloud Systems},
  shorttitle = {{{CloudScale}}},
  booktitle  = {Proceedings of the 2nd {{ACM Symposium}} on {{Cloud Computing}}},
  author     = {Shen, Zhiming and Subbiah, Sethuraman and Gu, Xiaohui and Wilkes, John},
  year       = {2011},
  month      = oct,
  series     = {{{SOCC}} '11},
  pages      = {1--14},
  publisher  = {{Association for Computing Machinery}},
  address    = {{New York, NY, USA}},
  doi        = {10.1145/2038916.2038921},
  abstract   = {Elastic resource scaling lets cloud systems meet application service level objectives (SLOs) with minimum resource provisioning costs. In this paper, we present CloudScale, a system that automates fine-grained elastic resource scaling for multi-tenant cloud computing infrastructures. CloudScale employs online resource demand prediction and prediction error handling to achieve adaptive resource allocation without assuming any prior knowledge about the applications running inside the cloud. CloudScale can resolve scaling conflicts between applications using migration, and integrates dynamic CPU voltage/frequency scaling to achieve energy savings with minimal effect on application SLOs. We have implemented CloudScale on top of Xen and conducted extensive experiments using a set of CPU and memory intensive applications (RUBiS, Hadoop, IBM System S). The results show that CloudScale can achieve significantly higher SLO conformance than other alternatives with low resource and energy cost. CloudScale is non-intrusive and light-weight, and imposes negligible overhead ({$<$} 2\% CPU in Domain 0) to the virtualized computing cluster.},
  isbn       = {978-1-4503-0976-9},
  keywords   = {cloud computing,energy-efficient computing,resource scaling}
}

@article{Barthe2019,
  title    = {Formal Verification of a Constant-Time Preserving {{C}} Compiler},
  author   = {Barthe, Gilles and Blazy, Sandrine and Gr{\'e}goire, Benjamin and Hutin, R{\'e}mi and Laporte, Vincent and Pichardie, David and Trieu, Alix},
  year     = {2019},
  month    = dec,
  journal  = {Proceedings of the ACM on Programming Languages},
  volume   = {4},
  number   = {POPL},
  pages    = {7:1--7:30},
  doi      = {10.1145/3371075},
  abstract = {Timing side-channels are arguably one of the main sources of vulnerabilities in cryptographic implementations. One effective mitigation against timing side-channels is to write programs that do not perform secret-dependent branches and memory accesses. This mitigation, known as "cryptographic constant-time", is adopted by several popular cryptographic libraries. This paper focuses on compilation of cryptographic constant-time programs, and more specifically on the following question: is the code generated by a realistic compiler for a constant-time source program itself provably constant-time? Surprisingly, we answer the question positively for a mildly modified version of the CompCert compiler, a formally verified and moderately optimizing compiler for C. Concretely, we modify the CompCert compiler to eliminate sources of potential leakage. Then, we instrument the operational semantics of CompCert intermediate languages so as to be able to capture cryptographic constant-time. Finally, we prove that the modified CompCert compiler preserves constant-time. Our mechanization maximizes reuse of the CompCert correctness proof, through the use of new proof techniques for proving preservation of constant-time. These techniques achieve complementary trade-offs between generality and tractability of proof effort, and are of independent interest.},
  keywords = {CompCert compiler,timing side-channels,verified compilation}
}

@inproceedings{Cauligi2019,
  title      = {{{FaCT}}: A {{DSL}} for Timing-Sensitive Computation},
  shorttitle = {{{FaCT}}},
  booktitle  = {Proceedings of the 40th {{ACM SIGPLAN Conference}} on {{Programming Language Design}} and {{Implementation}}},
  author     = {Cauligi, Sunjay and Soeller, Gary and Johannesmeyer, Brian and Brown, Fraser and Wahby, Riad S. and Renner, John and Gr{\'e}goire, Benjamin and Barthe, Gilles and Jhala, Ranjit and Stefan, Deian},
  year       = {2019},
  month      = jun,
  series     = {{{PLDI}} 2019},
  pages      = {174--189},
  publisher  = {{Association for Computing Machinery}},
  address    = {{New York, NY, USA}},
  doi        = {10.1145/3314221.3314605},
  abstract   = {Real-world cryptographic code is often written in a subset of C intended to execute in constant-time, thereby avoiding timing side channel vulnerabilities. This C subset eschews structured programming as we know it: if-statements, looping constructs, and procedural abstractions can leak timing information when handling sensitive data. The resulting obfuscation has led to subtle bugs, even in widely-used high-profile libraries like OpenSSL. To address the challenge of writing constant-time cryptographic code, we present FaCT, a crypto DSL that provides high-level but safe language constructs. The FaCT compiler uses a secrecy type system to automatically transform potentially timing-sensitive high-level code into low-level, constant-time LLVM bitcode. We develop the language and type system, formalize the constant-time transformation, and present an empirical evaluation that uses FaCT to implement core crypto routines from several open-source projects including OpenSSL, libsodium, and curve25519-donna. Our evaluation shows that FaCT's design makes it possible to write readable, high-level cryptographic code, with efficient, constant-time behavior.},
  isbn       = {978-1-4503-6712-7},
  keywords   = {cryptography,domain-specific language,program transformation}
}

@inproceedings{Gulavani2008,
  author    = {Gulavani, Bhargav S.
               and Gulwani, Sumit},
  editor    = {Gupta, Aarti
               and Malik, Sharad},
  title     = {A Numerical Abstract Domain Based on Expression Abstraction and Max Operator with Application in Timing Analysis},
  booktitle = {Computer Aided Verification},
  year      = {2008},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {370--384},
  abstract  = {This paper describes a precise numerical abstract domain for use in timing analysis. The numerical abstract domain is parameterized by a linear abstract domain and is constructed by means of two domain lifting operations. One domain lifting operation is based on the principle of expression abstraction (which involves defining a set of expressions and specifying their semantics using a collection of directed inference rules) and has a more general applicability. It lifts any given abstract domain to include reasoning about a given set of expressions whose semantics is abstracted using a set of axioms. The other domain lifting operation incorporates disjunctive reasoning into a given linear relational abstract domain via introduction of max expressions. We present experimental results demonstrating the potential of the new numerical abstract domain to discover a wide variety of timing bounds (including polynomial, disjunctive, logarithmic, exponential, etc.) for small C programs.},
  isbn      = {978-3-540-70545-1}
}

@article{Hoeting1999,
  issn      = {08834237},
  url       = {http://www.jstor.org/stable/2676803},
  abstract  = {Standard statistical practice ignores model uncertainty. Data analysts typically select a model from some class of models and then proceed as if the selected model had generated the data. This approach ignores the uncertainty in model selection, leading to over-confident inferences and decisions that are more risky than one thinks they are. Bayesian model averaging (BMA) provides a coherent mechanism for accounting for this model uncertainty. Several methods for implementing BMA have recently emerged. We discuss these methods and present a number of examples. In these examples, BMA provides improved out-of-sample predictive performance. We also provide a catalogue of currently available BMA software.},
  author    = {Jennifer A. Hoeting and David Madigan and Adrian E. Raftery and Chris T. Volinsky},
  journal   = {Statistical Science},
  number    = {4},
  pages     = {382--401},
  publisher = {Institute of Mathematical Statistics},
  title     = {Bayesian Model Averaging: A Tutorial},
  urldate   = {2024-06-13},
  volume    = {14},
  year      = {1999}
}

@article{Hermenegildo2005,
  title    = {Integrated program debugging, verification, and optimization using abstract interpretation (and the Ciao system preprocessor)},
  journal  = {Science of Computer Programming},
  volume   = {58},
  number   = {1},
  pages    = {115-140},
  year     = {2005},
  note     = {Special Issue on the Static Analysis Symposium 2003},
  issn     = {0167-6423},
  doi      = {https://doi.org/10.1016/j.scico.2005.02.006},
  url      = {https://www.sciencedirect.com/science/article/pii/S0167642305000468},
  author   = {Manuel V. Hermenegildo and Germán Puebla and Francisco Bueno and Pedro López-García},
  keywords = {Program development, Global analysis, Abstract interpretation, Debugging, Verification, Partial evaluation, Program transformation, Optimization, Parallelization, Resource control, Programming environments, Multi-Paradigm programming, (Constraint) Logic programming},
  abstract = {The technique of Abstract Interpretation has allowed the development of very sophisticated global program analyses which are at the same time provably correct and practical. We present in a tutorial fashion a novel program development framework which uses abstract interpretation as a fundamental tool. The framework uses modular, incremental abstract interpretation to obtain information about the program. This information is used to validate programs, to detect bugs with respect to partial specifications written using assertions (in the program itself and/or in system libraries), to generate and simplify run-time tests, and to perform high-level program transformations such as multiple abstract specialization, parallelization, and resource usage control, all in a provably correct way. In the case of validation and debugging, the assertions can refer to a variety of program points such as procedure entry, procedure exit, points within procedures, or global computations. The system can reason with much richer information than, for example, traditional types. This includes data structure shape (including pointer sharing), bounds on data structure sizes, and other operational variable instantiation properties, as well as procedure-level properties such as determinacy, termination, non-failure, and bounds on resource consumption (time or space cost). CiaoPP, the preprocessor of the Ciao multi-paradigm programming system, which implements the described functionality, will be used to illustrate the fundamental ideas.}
}

@article{Serrano2013,
  month     = {July},
  number    = {4-5 (S},
  note      = {Unpublished},
  journal   = {Theory and Practice of Logic Programming},
  volume    = {13},
  pages     = {1--15},
  year      = {2013},
  booktitle = {29th International Conference on Logic Programming},
  title     = {Sized Type Analysis for Logic Programs (Technical Communication)},
  publisher = {Cambridge University Press},
  issn      = {1471-0684},
  abstract  = {We present a novel analysis for relating the sizes of terms and subterms occurring at diferent argument positions in logic predicates. We extend and enrich the concept of sized type as a representation that incorporates structural (shape) information and allows expressing both lower and upper bounds on the size of a set of terms and their subterms at any position and depth. For example, expressing bounds on the length of lists of numbers, together with bounds on the values of all of their elements. The analysis is developed using abstract interpretation and the novel abstract operations are based on setting up and solving recurrence relations between sized types. It has been integrated, together with novel resource usage and cardinality analyses, in the abstract interpretation framework in the Ciao preprocessor, CiaoPP, in order to assess both the accuracy of the new size analysis and its usefulness in the resource usage estimation application. We show that the proposed sized types are a substantial improvement over the previous size analyses present in CiaoPP, and also benefit the resource analysis considerably, allowing the inference of equal or better bounds than comparable state of the art systems.},
  url       = {http://journals.cambridge.org/action/displayIssue?jid                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          = TLP&volumeId = 13&seriesId = 0&issueId = 4-5},
  author    = {Serrano Mena, Alejandro and L{\'o}pez Garc{\'i}a, Pedro and Bueno Carrillo, Francisco and Hermenegildo, Manuel V.}
}


@article{Serrano2014,
  title     = {Resource usage analysis of logic programs via abstract interpretation using sized types},
  author    = {Serrano, Alejandro and L{\'o}pez-Garc{\'\i}a, Pedro and Hermenegildo, Manuel V},
  journal   = {Theory and Practice of Logic Programming},
  volume    = {14},
  number    = {4-5},
  pages     = {739--754},
  year      = {2014},
  publisher = {Cambridge University Press}
}

@article{Lopez-Garcia2018,
  title   = {Interval-based resource usage verification by translation into Horn clauses and an application to energy consumption},
  author  = {Lopez-Garcia, P. and Darmawan, L. and Klemen, M. and Liqat, U. and Bueno, F. and Hermenegildo, M. V.},
  volume  = {18},
  doi     = {10.1017/S1471068418000042},
  number  = {2},
  journal = {Theory and Practice of Logic Programming},
  year    = {2018},
  pages   = {167-223}
}

@article{Tarjan1975,
  author     = {Tarjan, Robert Endre},
  title      = {Efficiency of a Good But Not Linear Set Union Algorithm},
  year       = {1975},
  issue_date = {April 1975},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {22},
  number     = {2},
  issn       = {0004-5411},
  url        = {https://doi.org/10.1145/321879.321884},
  doi        = {10.1145/321879.321884},
  journal    = {J. ACM},
  month      = apr,
  pages      = {215--225},
  numpages   = {11}
}

@article{Tarjan1984,
  author     = {Tarjan, Robert E. and van Leeuwen, Jan},
  title      = {Worst-case Analysis of Set Union Algorithms},
  year       = {1984},
  issue_date = {April 1984},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {31},
  number     = {2},
  issn       = {0004-5411},
  url        = {https://doi.org/10.1145/62.2160},
  doi        = {10.1145/62.2160},
  journal    = {J. ACM},
  month      = mar,
  pages      = {245--281},
  numpages   = {37}
}

@inproceedings{Kaplan2002,
  author    = {Kaplan, Haim and Shafrir, Nira and Tarjan, Robert E.},
  title     = {Union-find with deletions},
  year      = {2002},
  isbn      = {089871513X},
  publisher = {Society for Industrial and Applied Mathematics},
  address   = {USA},
  abstract  = {In the classical union-find problem we maintain a partition of a universe of n elements into disjoint sets subject to the operations union and find. The operation union(A, B, C) replaces sets A and B in the partition by their union, given the name C. The operation find(x) returns the name of the set containing the element x. In this paper we revisit the union-find problem in a context where the underlying partitioned universe is not fixed. Specifically, we allow a delete(x) operation which removes the element x from the set containing it. We consider both worst-case performance and amortized performance. In both settings the challenge is to dynamically keep the size of the structure representing each set proportional to the number of elements in the set which may now decrease as a result of deletions.For any fixed k, we describe a data structure that supports find and delete in O(logkn) worst-case time and union in O(k) worst-case time. This matches the best possible worst-case bounds for find and union in the classical setting. Furthermore, using an incremental global rebuilding technique we obtain a reduction converting any union-find data structure to a union-find with deletions data structure. Our reduction is such that the time bounds for find and union change only by a constant factor. The time it takes to delete an element x is the same as the time it takes to find the set containing x plus the time it takes to unite a singleton set with this set.In an amortized setting a classical data structure of Tarjan supports a sequence of m finds and at most n unions on a universe of n elements in O(n + mα(m + n, n, log n)) time where α(m, n, l) = min{k | Ak(⌊m/n⌋) > l} and Ai(j) is Ackermann's function as described in [6]. We refine the analysis of this data structure and show that in fact the cost of each find is proportional to the size of the corresponding set. Specifically, we show that one can pay for a sequence of union and find operations by charging a constant to each participating element and O(α(m, n, log(l))) for a find of an element in a set of size l. We also show how keep these amortized costs for each find and each participating element while allowing deletions. The amortized cost of deleting an element from a set of l elements is the same as the amortized cost of finding the element; namely, O(α(m, n, log(l))).},
  booktitle = {Proceedings of the Thirteenth Annual ACM-SIAM Symposium on Discrete Algorithms},
  pages     = {19--28},
  numpages  = {10},
  location  = {San Francisco, California},
  series    = {SODA '02}
}

@article{Alstrup2014,
  author     = {Alstrup, Stephen and Thorup, Mikkel and G\o{}rtz, Inge Li and Rauhe, Theis and Zwick, Uri},
  title      = {Union-Find with Constant Time Deletions},
  year       = {2014},
  issue_date = {October 2014},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {11},
  number     = {1},
  issn       = {1549-6325},
  url        = {https://doi.org/10.1145/2636922},
  doi        = {10.1145/2636922},
  abstract   = {A union-find data structure maintains a collection of disjoint sets under the operations makeset, union, and find. Kaplan, Shafrir, and Tarjan [SODA 2002] designed data structures for an extension of the union-find problem in which items of the sets maintained may be deleted. The cost of a delete operation in their implementations is essentially the same as the cost of a find operation; namely, O(log n) worst-case and O(α⌈ M/N⌉ (n)) amortized, where n is the number of items in the set returned by the find operation, N is the total number of makeset operations performed, M is the total number of find operations performed, and α⌈ M/N⌉(n) is a functional inverse of Ackermann’s function. They left open the question whether delete operations can be implemented more efficiently than find operations, for example, in o(log n) worst-case time. We resolve this open problem by presenting a relatively simple modification of the classical union-find data structure that supports delete, as well as makeset and union operations, in constant worst-case time, while still supporting find operations in O(log n) worst-case time and O(α⌈ M/N⌉ (n)) amortized time.Our analysis supplies, in particular, a very concise potential-based amortized analysis of the standard union-find data structure that yields an O(α⌈ M/N⌉ (n)) amortized bound on the cost of find operations. All previous potential-based analyses yielded the weaker amortized bound of O(α⌈ M/N⌉ (N)). Furthermore, our tighter analysis extends to one-path variants of the path compression technique such as path splitting.},
  journal    = {ACM Trans. Algorithms},
  month      = aug,
  articleno  = {6},
  numpages   = {28},
  keywords   = {disjoint sets, Union-find}
}

@inproceedings{Chargueraud2011,
  author    = {Chargu\'{e}raud, Arthur},
  title     = {Characteristic Formulae for the Verification of Imperative Programs},
  year      = {2011},
  isbn      = {9781450308656},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/2034773.2034828},
  booktitle = {Proceedings of the 16th ACM SIGPLAN International Conference on Functional Programming},
  pages     = {418--430},
  numpages  = {13},
  location  = {Tokyo, Japan}
}

@book{Bertot2004,
  title     = {Interactive Theorem Proving and Program Development},
  author    = {Bertot, Yves and Castéran Pierre},
  publisher = {Springer},
  address   = {Berlin},
  year      = {2004},
  doi       = {10.1007/978-3-662-07964-5}
}

@inproceedings{Norell2009,
  author    = {Norell, Ulf},
  title     = {Dependently typed programming in Agda},
  year      = {2009},
  isbn      = {9781605584201},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/1481861.1481862},
  doi       = {10.1145/1481861.1481862},
  abstract  = {Dependently typed languages have for a long time been used to describe proofs about programs. Traditionally, dependent types are used mostly for stating and proving the properties of the programs and not in defining the programs themselves. An impressive example is the certified compiler by Leroy (2006) implemented and proved correct in Coq (Bertot and Cast\'{e}ran 2004).Recently there has been an increased interest in dependently typed programming, where the aim is to write programs that use the dependent type system to a much higher degree. In this way a lot of the properties that were previously proved separately can be integrated in the type of the program, in many cases adding little or no complexity to the definition of the program. New languages, such as Epigram (McBride and McKinna 2004), are being designed, and existing languages are being extended with new features to accomodate these ideas, for instance the work on dependently typed programming in Coq by Sozeau (2007).This talk gives an overview of the Agda programming language (Norell 2007), whose main focus is on dependently typed programming. Agda provides a rich set of inductive types with a powerful mechanism for pattern matching, allowing dependently typed programs to be written with minimal fuss. To read about programming in Agda, see the lecture notes from the Advanced Functional Programming summer school (Norell 2008) and the work by Oury and Swierstra (2008).In the talk a number of examples of interesting dependently typed programs chosen from the domain of programming language implementation are presented as they are implemented in Agda.},
  booktitle = {Proceedings of the 4th International Workshop on Types in Language Design and Implementation},
  pages     = {1--2},
  numpages  = {2},
  keywords  = {programming, dependent types},
  location  = {Savannah, GA, USA},
  series    = {TLDI '09}
}

@inproceedings{DeMoura2008,
  author    = {De Moura, Leonardo and Bj\o{}rner, Nikolaj},
  title     = {Z3: an efficient SMT solver},
  year      = {2008},
  isbn      = {3540787992},
  publisher = {Springer-Verlag},
  address   = {Berlin, Heidelberg},
  abstract  = {Satisfiability Modulo Theories (SMT) problem is a decision problem for logical first order formulas with respect to combinations of background theories such as: arithmetic, bit-vectors, arrays, and uninterpreted functions. Z3 is a new and efficient SMT Solver freely available from Microsoft Research. It is used in various software verification and analysis applications.},
  booktitle = {Proceedings of the Theory and Practice of Software, 14th International Conference on Tools and Algorithms for the Construction and Analysis of Systems},
  pages     = {337--340},
  numpages  = {4},
  location  = {Budapest, Hungary},
  series    = {TACAS'08/ETAPS'08}
}

@article{Rustenholz2024,
  title   = {A Machine Learning-Based Approach for Solving Recurrence Relations and Its use in Cost Analysis of Logic Programs},
  volume  = {24},
  doi     = {10.1017/S1471068424000413},
  number  = {6},
  journal = {Theory and Practice of Logic Programming},
  author  = {Louis Rustenholz and
             Maximiliano Klemen and
             Miguel {\'{A}}. Carreira{-}Perpi{\~{n}}{\'{a}}n and
             Pedro L{\'{o}}pez{-}Garc{\'{\i}}a},
  year    = {2024},
  pages   = {1163--1207}
}

@inproceedings{Rustenholz2024sas,
  author    = {Rustenholz, Louis and L\'{o}pez-Garc\'{\i}a, Pedro and Morales, Jos\'{e} F. and Hermenegildo, Manuel V.},
  title     = {An Order Theory Framework of Recurrence Equations for Static Cost Analysis -- Dynamic Inference of Non-Linear Inequality Invariants},
  year      = {2024},
  isbn      = {978-3-031-74775-5},
  publisher = {Springer-Verlag},
  address   = {Berlin, Heidelberg},
  url       = {https://doi.org/10.1007/978-3-031-74776-2_14},
  doi       = {10.1007/978-3-031-74776-2_14},
  abstract  = {Recurrence equations have played a central role in static cost analysis,&nbsp;where they can be viewed as abstractions of programs and used to&nbsp;infer resource usage information without actually running the programs&nbsp;with concrete data. Such information is typically represented as functions of input data sizes. More generally, recurrence equations have been increasingly&nbsp;used to automatically obtain non-linear numerical invariants. However, state-of-the-art recurrence solvers and cost analysers suffer&nbsp;from serious limitations when dealing with the (complex) features&nbsp;of recurrences arising from&nbsp;cost analyses. We address this challenge by developing a novel order-theoretical framework where recurrences are viewed as operators and&nbsp;their solutions as fixpoints, which allows leveraging powerful pre/postfixpoint search techniques. We prove useful properties&nbsp;and provide principles and insights that enable us to develop techniques and combine them&nbsp;to design&nbsp;new solvers. We have also implemented and experimentally evaluated&nbsp;an optimisation-based instantiation of the proposed approach. The results are quite promising: our prototype outperforms state-of-the-art cost analysers and recurrence solvers, and can&nbsp;infer tight non-linear lower/upper bounds, in a reasonable time, for complex recurrences representing diverse program behaviours.},
  booktitle = {Static Analysis: 31st International Symposium, SAS 2024, Pasadena, CA, USA, October 20--22, 2024, Proceedings},
  pages     = {352--385},
  numpages  = {34},
  keywords  = {Static Cost Analysis, Resource Usage Analysis, Static Analysis, Recurrence Equations},
  location  = {Pasadena, CA, USA}
}
